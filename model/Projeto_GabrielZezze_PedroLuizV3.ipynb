{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-67506f34-d151-448b-95ba-10aaae723fd7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Drawing Guesser \n",
    "## Pedro Luiz & Gabriel Zezze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-582329ba-9020-41ec-a821-d4d8196c212c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### O dataset\n",
    "O drawing guesser se baseia no [dataset de desenhos dispopnibilizados pelo Google](https://github.com/googlecreativelab/quickdraw-dataset) gerado através do jogo [QuickDraw](https://quickdraw.withgoogle.com/).\n",
    "\n",
    "O dataset completo consiste de 150 mil desenhos que são imagens bitmap de 28x28 para cada categoria sendo que há 345 categorias disponibilizadas.\n",
    "\n",
    "O intuito do drawing guesser é simular o proprio QuickDraw, ou seja, fazer classificações do desenho enquanto o jogador desenha, porém com um número limitado de catogrias (x) e uma rede neural própria treinada a partir do dataset disponibilizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-d9d5ef69-0f53-4666-b723-9828344b40a2",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### O problema\n",
    "\n",
    "Este é um problema de classifição multiclasse dos desenhos dispoinibilizados no dataset. Para realizar essa classificação vamos utilizar uma rede convulacional que será explicada detalhadamente abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-afc88602-3533-45b6-bdac-b1ea73af36f9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout, BatchNormalization\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00001-747ea66f-189b-4956-9891-dff7582e5f18",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#DECLARE CONSTANTS\n",
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "NUM_FILES = 35000\n",
    "RF_NUM_FILES = 10000\n",
    "N_EPOCHS = 300\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-6d2f6b48-249f-4fa4-918a-7dae7bbf8bee",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Extração de dados\n",
    "\n",
    "O dataset utilizado disponibiliza arquivos do tipo numpy bit array, que quando lidos com a função `numpy.load` retorna um numpy array. Contudo, esse array possui apenas uma dimensão. Dessa forma, é necessário fazer o reshape de cada imagem lida para se tornar uma matriz 28x28. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-e96aecac-cd38-4d76-9a78-91033a447e41",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 539,
    "execution_start": 1623245615866,
    "source_hash": "7b74984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/book.npy', './data/bus.npy', './data/mushroom.npy', './data/camel.npy', './data/apple.npy', './data/airplane.npy', './data/cactus.npy', './data/butterfly.npy', './data/bird.npy', './data/hand.npy', './data/cake.npy', './data/axe.npy', './data/banana.npy', './data/calendar.npy', './data/alarm clock.npy', './data/donut.npy', './data/basketball.npy', './data/crayon.npy', './data/bed.npy', './data/barn.npy']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#GETTING ALL FILE NAMES\n",
    "data_files = os.listdir('./data/')\n",
    "data_files = [f'./data/{file}' for file in data_files]\n",
    "if data_files.count('./data/.DS_Store') > 0:\n",
    "    data_files.remove('./data/.DS_Store')\n",
    "N_CATEGORIES = len(data_files)\n",
    "\n",
    "# data_files = [\n",
    "#     '../data/book.npy',\n",
    "#     '../data/bus.npy',\n",
    "#     '../data/camel.npy',\n",
    "#     '../data/apple.npy', \n",
    "#     '../data/airplane.npy',\n",
    "#     '../data/cactus.npy',\n",
    "#     '../data/bush.npy',\n",
    "#     '../data/butterfly.npy',\n",
    "#     '../data/calculator.npy',\n",
    "#     '../data/bird.npy',\n",
    "#     '../data/ambulance.npy',\n",
    "#     '../data/cake.npy',\n",
    "#     '../data/beach.npy',\n",
    "#     '../data/axe.npy',\n",
    "#     '../data/banana.npy',\n",
    "#     '../data/calendar.npy',\n",
    "#     '../data/alarm clock.npy',\n",
    "#     '../data/basketball.npy',\n",
    "#     '../data/bed.npy',\n",
    "#     '../data/barn.npy'\n",
    "# ]\n",
    "\n",
    "print(data_files)\n",
    "print(N_CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00003-51ec2a30-1091-460b-9666-d681a3415ff4",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#READING FILES AND POPULATING TOTAL X AND Y\n",
    "all_drawings = []\n",
    "all_categories = []\n",
    "\n",
    "for idx, file in enumerate(data_files):\n",
    "    data = np.load(file)[:NUM_FILES]\n",
    "    for d in data:\n",
    "        reshaped_img = np.array(np.reshape(d, (-1, 28))).astype(np.float32)\n",
    "        \n",
    "        all_drawings.append(reshaped_img)\n",
    "        all_categories.append(idx)\n",
    "\n",
    "all_drawings = np.array(all_drawings)\n",
    "all_categories = np.array(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-d97d4154-4ce2-4406-bd2f-6928226375e8",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Selecao de dados entre dados de treinamento e teste\n",
    "\n",
    "Antes de qualquer treinamento ou teste em cima dos dados é necessário separá-los em dados de treinamento e teste sendo 20% dos dados seprados para teste e o restante para treinamento. \n",
    "\n",
    "Após essa separação os dados de trinamento serão divididos mais uma vez, sendo que 80% deste dados serao para treinamento do modelo e 20% para validação do treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00004-126006f2-6480-49d7-85f7-8e155808e851",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(all_drawings, all_categories, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-b5116cb9-56d0-4654-a7c8-d59d1a24fe4c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Estabelecendo uma base\n",
    "Antes de iniciar a criação da rede convolucional, precisamos de uma base para saber se nosso modelo faz classificaçõeses melhores que modelos aleatórios. Para isso vamos utilizar o classificador Random Forrest para estabelecer um mínimo de performance para nosso modelo convolucional. Dessa forma, se a rede concolucional criada possuir desempenho similar ao classificador aleatório, não podemos dizer que obtivemos qualquer sucesso.\n",
    "\n",
    "Como o classificador Random forrest recebe dados de treinamento de uma forma diferente (Vetores de no máximo duas dimensões) que uma rede convolucional, precisamos mudar o formato das features para treiná-lo.\n",
    "Após treinar o classificador Random forest usamos o método `cross_val_score` para separarmos os dados de treinamento em 5 divisoes. Esse método combina 4 divisões para treinamento e a divisão restante para validação. Por fim, obtivemos os seguintes valores de acurácia de validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-7582ac69-3e78-41c1-beec-cfd7c433f9c8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf_drawings = np.array([all_drawings[i:i + RF_NUM_FILES] for i in range(0, len(all_drawings), NUM_FILES)])\n",
    "rf_drawings = np.concatenate([draw for draw in rf_drawings])\n",
    "\n",
    "rf_categories = np.array([all_categories[i:i + RF_NUM_FILES] for i in range(0, len(all_categories), NUM_FILES)])\n",
    "rf_categories = np.concatenate([cat for cat in rf_categories])\n",
    "\n",
    "X_rf_train_full, X_rf_test, y_rf_train_full, y_rf_test = train_test_split(rf_drawings, rf_categories, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "random_forest_X_train = np.array([x.flatten() for x in X_rf_train_full])\n",
    "random_forrest_clf = RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1)\n",
    "\n",
    "cv_rf_score = cross_val_score(random_forrest_clf, random_forest_X_train, y_rf_train_full, cv=5, n_jobs=-1)\n",
    "for idx, val in enumerate(cv_rf_score):\n",
    "    print(f\"{idx+1}:  {round(val*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-9039431f-d71f-40e3-a519-9557a0b76e45",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Montagem da rede convolucional\n",
    "\n",
    "O modelo criado possui 3 conjuntos de camadas convolucionais seguidas de um max pooling. Os filtros da camada convolucional começam em 8 e vão dobrando, já para o kernel initializer foi utilizado o padrão que é o `glorot_uniform` de tamanho 3x3. Essas primeiras camadas tem o objetivo de destacar as features únicas(detalhes) de cada categoria. Em seguida é realizado o Flatten para transformar todas as camadas em uma array 1D e um Batch Normalization para padronizar os valores, ou seja, centralizar sua média em 0 e o desvio padrão em 1. Também foi adicionada uma camada de Dropout para evitar o overfitting. Na sequência, os inputs normalizados  são passados para uma camada Densa, a qual recebe dois parametros, número de neurônios e função de ativação que sera usada, assim a camada densa recebe as features, multiplica pelos respectivos pesos e soma esta multiplicação para finalmente passar pela funcao de ativação. Em seguida é aplicada mais uma batch normalization e um dropout. Por fim, é aplicada mais uma camada Dense com units = número de categorias, com a função de ativação soft max, para obter o resultado da classificação.\n",
    "\n",
    "#### Entradas e saídas das camadas\n",
    "```\n",
    "(28, 28, 1) -> Primeira camada Conv2D -> (28, 28, 8)\n",
    "(28, 28, 8) -> Primerira camada Maxpooling2D -> (14, 14, 8)\n",
    "(14, 14, 8) -> Segunda camada Conv2D -> (14, 14, 16)\n",
    "(14, 14, 16) -> Segunda camada Maxpooling2D -> (7, 7, 16)\n",
    "(7, 7, 16) -> Terceira camada Conv2D -> (7, 7, 32)\n",
    "(7, 7, 32) -> Terceira camada Maxpooling2D -> (4, 4, 32)\n",
    "(4, 4, 32) -> Flatten -> (512)\n",
    "(512) -> Dense -> (30)\n",
    "(30) -> Dense -> (N)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00008-ab0e3ec3-8cf3-4341-895a-36d0e5291014",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "slice_index = int(len(X_train_full)*0.8)\n",
    "\n",
    "X_train = X_train_full[:slice_index][..., np.newaxis]\n",
    "X_valid = X_train_full[slice_index:][..., np.newaxis]\n",
    "\n",
    "y_train = y_train_full[:slice_index][..., np.newaxis]\n",
    "y_valid = y_train_full[slice_index:][..., np.newaxis]\n",
    "\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00009-c41bd223-23d0-402f-90f0-2fdf355e7eab",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    Conv2D(filters=8, kernel_size=3,padding=\"same\", activation=\"relu\", input_shape=(IMG_HEIGHT,IMG_WIDTH,1)),\n",
    "    MaxPool2D(pool_size=2),\n",
    "\n",
    "    Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "\n",
    "    Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5, seed=RANDOM_SEED),\n",
    "    Dense(units=30,activation=\"relu\"),\n",
    "    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5, seed=RANDOM_SEED),\n",
    "    Dense(units=N_CATEGORIES, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00010-798a5aaa-0fb4-41e4-baf3-2b1714d92cfa",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00011-5b757315-6ffb-47bb-8256-acb849bf826b",
    "deepnote_cell_type": "code",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1697/1697 [==============================] - 12s 4ms/step - loss: 2.5430 - accuracy: 0.2696 - val_loss: 1.5124 - val_accuracy: 0.6212\n",
      "Epoch 2/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 1.7055 - accuracy: 0.4942 - val_loss: 1.0901 - val_accuracy: 0.7275\n",
      "Epoch 3/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 1.4047 - accuracy: 0.5863 - val_loss: 0.8934 - val_accuracy: 0.7703\n",
      "Epoch 4/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 1.2448 - accuracy: 0.6352 - val_loss: 0.7832 - val_accuracy: 0.7934\n",
      "Epoch 5/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 1.1461 - accuracy: 0.6670 - val_loss: 0.7133 - val_accuracy: 0.8089\n",
      "Epoch 6/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 1.0819 - accuracy: 0.6883 - val_loss: 0.6719 - val_accuracy: 0.8203\n",
      "Epoch 7/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 1.0355 - accuracy: 0.7021 - val_loss: 0.6358 - val_accuracy: 0.8290\n",
      "Epoch 8/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 1.0005 - accuracy: 0.7144 - val_loss: 0.6114 - val_accuracy: 0.8352\n",
      "Epoch 9/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.9726 - accuracy: 0.7235 - val_loss: 0.5912 - val_accuracy: 0.8410\n",
      "Epoch 10/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.9482 - accuracy: 0.7317 - val_loss: 0.5717 - val_accuracy: 0.8461\n",
      "Epoch 11/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.9280 - accuracy: 0.7380 - val_loss: 0.5589 - val_accuracy: 0.8486\n",
      "Epoch 12/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.9096 - accuracy: 0.7433 - val_loss: 0.5457 - val_accuracy: 0.8526\n",
      "Epoch 13/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8946 - accuracy: 0.7488 - val_loss: 0.5393 - val_accuracy: 0.8540\n",
      "Epoch 14/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8821 - accuracy: 0.7528 - val_loss: 0.5302 - val_accuracy: 0.8564\n",
      "Epoch 15/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8683 - accuracy: 0.7579 - val_loss: 0.5173 - val_accuracy: 0.8605\n",
      "Epoch 16/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8581 - accuracy: 0.7604 - val_loss: 0.5073 - val_accuracy: 0.8625\n",
      "Epoch 17/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8487 - accuracy: 0.7635 - val_loss: 0.5018 - val_accuracy: 0.8643\n",
      "Epoch 18/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8373 - accuracy: 0.7675 - val_loss: 0.4937 - val_accuracy: 0.8666\n",
      "Epoch 19/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8307 - accuracy: 0.7698 - val_loss: 0.4890 - val_accuracy: 0.8683\n",
      "Epoch 20/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8216 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.8692\n",
      "Epoch 21/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8151 - accuracy: 0.7743 - val_loss: 0.4806 - val_accuracy: 0.8696\n",
      "Epoch 22/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8071 - accuracy: 0.7778 - val_loss: 0.4741 - val_accuracy: 0.8713\n",
      "Epoch 23/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.8016 - accuracy: 0.7789 - val_loss: 0.4709 - val_accuracy: 0.8723\n",
      "Epoch 24/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7963 - accuracy: 0.7804 - val_loss: 0.4669 - val_accuracy: 0.8731\n",
      "Epoch 25/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7927 - accuracy: 0.7819 - val_loss: 0.4629 - val_accuracy: 0.8745\n",
      "Epoch 26/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7867 - accuracy: 0.7832 - val_loss: 0.4616 - val_accuracy: 0.8750\n",
      "Epoch 27/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7829 - accuracy: 0.7842 - val_loss: 0.4592 - val_accuracy: 0.8757\n",
      "Epoch 28/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7789 - accuracy: 0.7858 - val_loss: 0.4563 - val_accuracy: 0.8763\n",
      "Epoch 29/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7744 - accuracy: 0.7868 - val_loss: 0.4530 - val_accuracy: 0.8771\n",
      "Epoch 30/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7707 - accuracy: 0.7883 - val_loss: 0.4527 - val_accuracy: 0.8762\n",
      "Epoch 31/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7690 - accuracy: 0.7885 - val_loss: 0.4483 - val_accuracy: 0.8787\n",
      "Epoch 32/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7619 - accuracy: 0.7906 - val_loss: 0.4458 - val_accuracy: 0.8786\n",
      "Epoch 33/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7604 - accuracy: 0.7913 - val_loss: 0.4452 - val_accuracy: 0.8790\n",
      "Epoch 34/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7586 - accuracy: 0.7919 - val_loss: 0.4461 - val_accuracy: 0.8786\n",
      "Epoch 35/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7570 - accuracy: 0.7927 - val_loss: 0.4443 - val_accuracy: 0.8789\n",
      "Epoch 36/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7508 - accuracy: 0.7941 - val_loss: 0.4378 - val_accuracy: 0.8816\n",
      "Epoch 37/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7499 - accuracy: 0.7942 - val_loss: 0.4377 - val_accuracy: 0.8814\n",
      "Epoch 38/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7449 - accuracy: 0.7958 - val_loss: 0.4355 - val_accuracy: 0.8815\n",
      "Epoch 39/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7443 - accuracy: 0.7961 - val_loss: 0.4377 - val_accuracy: 0.8813\n",
      "Epoch 40/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7401 - accuracy: 0.7976 - val_loss: 0.4325 - val_accuracy: 0.8819\n",
      "Epoch 41/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7379 - accuracy: 0.7981 - val_loss: 0.4365 - val_accuracy: 0.8806\n",
      "Epoch 42/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7367 - accuracy: 0.7979 - val_loss: 0.4332 - val_accuracy: 0.8825\n",
      "Epoch 43/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7337 - accuracy: 0.7991 - val_loss: 0.4305 - val_accuracy: 0.8831\n",
      "Epoch 44/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7341 - accuracy: 0.7996 - val_loss: 0.4270 - val_accuracy: 0.8837\n",
      "Epoch 45/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7304 - accuracy: 0.8004 - val_loss: 0.4260 - val_accuracy: 0.8841\n",
      "Epoch 46/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7323 - accuracy: 0.7999 - val_loss: 0.4304 - val_accuracy: 0.8825\n",
      "Epoch 47/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7275 - accuracy: 0.8015 - val_loss: 0.4243 - val_accuracy: 0.8844\n",
      "Epoch 48/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7247 - accuracy: 0.8023 - val_loss: 0.4272 - val_accuracy: 0.8838\n",
      "Epoch 49/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7245 - accuracy: 0.8027 - val_loss: 0.4226 - val_accuracy: 0.8848\n",
      "Epoch 50/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7218 - accuracy: 0.8027 - val_loss: 0.4227 - val_accuracy: 0.8852\n",
      "Epoch 51/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7217 - accuracy: 0.8030 - val_loss: 0.4229 - val_accuracy: 0.8851\n",
      "Epoch 52/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7198 - accuracy: 0.8036 - val_loss: 0.4174 - val_accuracy: 0.8861\n",
      "Epoch 53/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7160 - accuracy: 0.8055 - val_loss: 0.4246 - val_accuracy: 0.8846\n",
      "Epoch 54/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7194 - accuracy: 0.8035 - val_loss: 0.4184 - val_accuracy: 0.8858\n",
      "Epoch 55/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7162 - accuracy: 0.8048 - val_loss: 0.4185 - val_accuracy: 0.8857\n",
      "Epoch 56/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7123 - accuracy: 0.8056 - val_loss: 0.4165 - val_accuracy: 0.8866\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7127 - accuracy: 0.8060 - val_loss: 0.4167 - val_accuracy: 0.8866\n",
      "Epoch 58/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7113 - accuracy: 0.8066 - val_loss: 0.4144 - val_accuracy: 0.8875\n",
      "Epoch 59/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7103 - accuracy: 0.8066 - val_loss: 0.4145 - val_accuracy: 0.8877\n",
      "Epoch 60/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7099 - accuracy: 0.8069 - val_loss: 0.4131 - val_accuracy: 0.8876\n",
      "Epoch 61/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7078 - accuracy: 0.8068 - val_loss: 0.4144 - val_accuracy: 0.8876\n",
      "Epoch 62/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7053 - accuracy: 0.8076 - val_loss: 0.4108 - val_accuracy: 0.8879\n",
      "Epoch 63/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7056 - accuracy: 0.8075 - val_loss: 0.4105 - val_accuracy: 0.8888\n",
      "Epoch 64/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7033 - accuracy: 0.8087 - val_loss: 0.4105 - val_accuracy: 0.8883\n",
      "Epoch 65/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7049 - accuracy: 0.8089 - val_loss: 0.4088 - val_accuracy: 0.8895\n",
      "Epoch 66/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7023 - accuracy: 0.8084 - val_loss: 0.4125 - val_accuracy: 0.8879\n",
      "Epoch 67/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7002 - accuracy: 0.8091 - val_loss: 0.4104 - val_accuracy: 0.8888\n",
      "Epoch 68/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.7003 - accuracy: 0.8095 - val_loss: 0.4086 - val_accuracy: 0.8896\n",
      "Epoch 69/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6993 - accuracy: 0.8096 - val_loss: 0.4072 - val_accuracy: 0.8899\n",
      "Epoch 70/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6974 - accuracy: 0.8100 - val_loss: 0.4075 - val_accuracy: 0.8892\n",
      "Epoch 71/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6960 - accuracy: 0.8105 - val_loss: 0.4072 - val_accuracy: 0.8902\n",
      "Epoch 72/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6952 - accuracy: 0.8110 - val_loss: 0.4052 - val_accuracy: 0.8902\n",
      "Epoch 73/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6961 - accuracy: 0.8100 - val_loss: 0.4042 - val_accuracy: 0.8909\n",
      "Epoch 74/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6963 - accuracy: 0.8106 - val_loss: 0.4050 - val_accuracy: 0.8905\n",
      "Epoch 75/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6948 - accuracy: 0.8112 - val_loss: 0.4053 - val_accuracy: 0.8902\n",
      "Epoch 76/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6939 - accuracy: 0.8107 - val_loss: 0.4035 - val_accuracy: 0.8907\n",
      "Epoch 77/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6932 - accuracy: 0.8115 - val_loss: 0.4052 - val_accuracy: 0.8902\n",
      "Epoch 78/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6900 - accuracy: 0.8121 - val_loss: 0.4030 - val_accuracy: 0.8906\n",
      "Epoch 79/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6894 - accuracy: 0.8121 - val_loss: 0.4040 - val_accuracy: 0.8904\n",
      "Epoch 80/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6894 - accuracy: 0.8124 - val_loss: 0.4031 - val_accuracy: 0.8910\n",
      "Epoch 81/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6908 - accuracy: 0.8121 - val_loss: 0.4018 - val_accuracy: 0.8914\n",
      "Epoch 82/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6877 - accuracy: 0.8123 - val_loss: 0.4011 - val_accuracy: 0.8911\n",
      "Epoch 83/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6900 - accuracy: 0.8119 - val_loss: 0.4004 - val_accuracy: 0.8919\n",
      "Epoch 84/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6876 - accuracy: 0.8132 - val_loss: 0.4011 - val_accuracy: 0.8910\n",
      "Epoch 85/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6864 - accuracy: 0.8127 - val_loss: 0.3998 - val_accuracy: 0.8920\n",
      "Epoch 86/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6875 - accuracy: 0.8126 - val_loss: 0.4028 - val_accuracy: 0.8908\n",
      "Epoch 87/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6844 - accuracy: 0.8135 - val_loss: 0.3980 - val_accuracy: 0.8921\n",
      "Epoch 88/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6852 - accuracy: 0.8132 - val_loss: 0.4009 - val_accuracy: 0.8913\n",
      "Epoch 89/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6847 - accuracy: 0.8134 - val_loss: 0.4020 - val_accuracy: 0.8913\n",
      "Epoch 90/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6828 - accuracy: 0.8137 - val_loss: 0.3970 - val_accuracy: 0.8924\n",
      "Epoch 91/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6834 - accuracy: 0.8137 - val_loss: 0.3976 - val_accuracy: 0.8920\n",
      "Epoch 92/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6827 - accuracy: 0.8142 - val_loss: 0.3983 - val_accuracy: 0.8921\n",
      "Epoch 93/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6825 - accuracy: 0.8143 - val_loss: 0.3974 - val_accuracy: 0.8928\n",
      "Epoch 94/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6816 - accuracy: 0.8150 - val_loss: 0.3989 - val_accuracy: 0.8916\n",
      "Epoch 95/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6801 - accuracy: 0.8144 - val_loss: 0.3983 - val_accuracy: 0.8922\n",
      "Epoch 96/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6807 - accuracy: 0.8148 - val_loss: 0.3969 - val_accuracy: 0.8926\n",
      "Epoch 97/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6777 - accuracy: 0.8146 - val_loss: 0.4007 - val_accuracy: 0.8910\n",
      "Epoch 98/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6794 - accuracy: 0.8148 - val_loss: 0.3960 - val_accuracy: 0.8926\n",
      "Epoch 99/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6789 - accuracy: 0.8157 - val_loss: 0.3957 - val_accuracy: 0.8925\n",
      "Epoch 100/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6796 - accuracy: 0.8150 - val_loss: 0.3966 - val_accuracy: 0.8926\n",
      "Epoch 101/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6768 - accuracy: 0.8151 - val_loss: 0.3943 - val_accuracy: 0.8929\n",
      "Epoch 102/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6775 - accuracy: 0.8160 - val_loss: 0.3934 - val_accuracy: 0.8933\n",
      "Epoch 103/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6778 - accuracy: 0.8153 - val_loss: 0.3951 - val_accuracy: 0.8929\n",
      "Epoch 104/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6760 - accuracy: 0.8155 - val_loss: 0.3946 - val_accuracy: 0.8932\n",
      "Epoch 105/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6745 - accuracy: 0.8165 - val_loss: 0.3931 - val_accuracy: 0.8931\n",
      "Epoch 106/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6750 - accuracy: 0.8162 - val_loss: 0.3943 - val_accuracy: 0.8930\n",
      "Epoch 107/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6745 - accuracy: 0.8163 - val_loss: 0.3936 - val_accuracy: 0.8933\n",
      "Epoch 108/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6722 - accuracy: 0.8171 - val_loss: 0.3921 - val_accuracy: 0.8933\n",
      "Epoch 109/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6731 - accuracy: 0.8162 - val_loss: 0.3928 - val_accuracy: 0.8933\n",
      "Epoch 110/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6714 - accuracy: 0.8168 - val_loss: 0.3931 - val_accuracy: 0.8932\n",
      "Epoch 111/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6727 - accuracy: 0.8165 - val_loss: 0.3928 - val_accuracy: 0.8938\n",
      "Epoch 112/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6711 - accuracy: 0.8175 - val_loss: 0.3926 - val_accuracy: 0.8936\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6723 - accuracy: 0.8167 - val_loss: 0.3908 - val_accuracy: 0.8944\n",
      "Epoch 114/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6704 - accuracy: 0.8176 - val_loss: 0.3913 - val_accuracy: 0.8940\n",
      "Epoch 115/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6718 - accuracy: 0.8169 - val_loss: 0.3921 - val_accuracy: 0.8937\n",
      "Epoch 116/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6685 - accuracy: 0.8181 - val_loss: 0.3920 - val_accuracy: 0.8938\n",
      "Epoch 117/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6677 - accuracy: 0.8178 - val_loss: 0.3914 - val_accuracy: 0.8945\n",
      "Epoch 118/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6686 - accuracy: 0.8177 - val_loss: 0.3906 - val_accuracy: 0.8941\n",
      "Epoch 119/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6678 - accuracy: 0.8182 - val_loss: 0.3921 - val_accuracy: 0.8937\n",
      "Epoch 120/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6685 - accuracy: 0.8178 - val_loss: 0.3906 - val_accuracy: 0.8943\n",
      "Epoch 121/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6667 - accuracy: 0.8185 - val_loss: 0.3897 - val_accuracy: 0.8943\n",
      "Epoch 122/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6663 - accuracy: 0.8191 - val_loss: 0.3885 - val_accuracy: 0.8948\n",
      "Epoch 123/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6656 - accuracy: 0.8186 - val_loss: 0.3911 - val_accuracy: 0.8941\n",
      "Epoch 124/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6653 - accuracy: 0.8189 - val_loss: 0.3904 - val_accuracy: 0.8940\n",
      "Epoch 125/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6641 - accuracy: 0.8189 - val_loss: 0.3885 - val_accuracy: 0.8943\n",
      "Epoch 126/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6666 - accuracy: 0.8181 - val_loss: 0.3911 - val_accuracy: 0.8932\n",
      "Epoch 127/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6654 - accuracy: 0.8186 - val_loss: 0.3897 - val_accuracy: 0.8949\n",
      "Epoch 128/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6656 - accuracy: 0.8184 - val_loss: 0.3881 - val_accuracy: 0.8949\n",
      "Epoch 129/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6653 - accuracy: 0.8189 - val_loss: 0.3891 - val_accuracy: 0.8948\n",
      "Epoch 130/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6649 - accuracy: 0.8194 - val_loss: 0.3912 - val_accuracy: 0.8935\n",
      "Epoch 131/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6649 - accuracy: 0.8190 - val_loss: 0.3881 - val_accuracy: 0.8948\n",
      "Epoch 132/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6639 - accuracy: 0.8188 - val_loss: 0.3871 - val_accuracy: 0.8950\n",
      "Epoch 133/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6633 - accuracy: 0.8185 - val_loss: 0.3853 - val_accuracy: 0.8955\n",
      "Epoch 134/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6617 - accuracy: 0.8195 - val_loss: 0.3862 - val_accuracy: 0.8957\n",
      "Epoch 135/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6625 - accuracy: 0.8189 - val_loss: 0.3874 - val_accuracy: 0.8948\n",
      "Epoch 136/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6598 - accuracy: 0.8195 - val_loss: 0.3878 - val_accuracy: 0.8953\n",
      "Epoch 137/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6633 - accuracy: 0.8189 - val_loss: 0.3860 - val_accuracy: 0.8955\n",
      "Epoch 138/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6601 - accuracy: 0.8196 - val_loss: 0.3866 - val_accuracy: 0.8955\n",
      "Epoch 139/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6608 - accuracy: 0.8201 - val_loss: 0.3865 - val_accuracy: 0.8952\n",
      "Epoch 140/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6609 - accuracy: 0.8192 - val_loss: 0.3880 - val_accuracy: 0.8947\n",
      "Epoch 141/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6593 - accuracy: 0.8202 - val_loss: 0.3858 - val_accuracy: 0.8958\n",
      "Epoch 142/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6587 - accuracy: 0.8204 - val_loss: 0.3860 - val_accuracy: 0.8957\n",
      "Epoch 143/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6603 - accuracy: 0.8202 - val_loss: 0.3854 - val_accuracy: 0.8953\n",
      "Epoch 144/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6601 - accuracy: 0.8198 - val_loss: 0.3846 - val_accuracy: 0.8963\n",
      "Epoch 145/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6587 - accuracy: 0.8206 - val_loss: 0.3838 - val_accuracy: 0.8960\n",
      "Epoch 146/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6596 - accuracy: 0.8199 - val_loss: 0.3858 - val_accuracy: 0.8956\n",
      "Epoch 147/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6559 - accuracy: 0.8210 - val_loss: 0.3840 - val_accuracy: 0.8957\n",
      "Epoch 148/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6597 - accuracy: 0.8205 - val_loss: 0.3858 - val_accuracy: 0.8955\n",
      "Epoch 149/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6592 - accuracy: 0.8201 - val_loss: 0.3865 - val_accuracy: 0.8950\n",
      "Epoch 150/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6575 - accuracy: 0.8212 - val_loss: 0.3854 - val_accuracy: 0.8958\n",
      "Epoch 151/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6576 - accuracy: 0.8207 - val_loss: 0.3854 - val_accuracy: 0.8961\n",
      "Epoch 152/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6580 - accuracy: 0.8202 - val_loss: 0.3843 - val_accuracy: 0.8956\n",
      "Epoch 153/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6568 - accuracy: 0.8205 - val_loss: 0.3837 - val_accuracy: 0.8961\n",
      "Epoch 154/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6578 - accuracy: 0.8206 - val_loss: 0.3844 - val_accuracy: 0.8958\n",
      "Epoch 155/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6586 - accuracy: 0.8205 - val_loss: 0.3840 - val_accuracy: 0.8959\n",
      "Epoch 156/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6560 - accuracy: 0.8210 - val_loss: 0.3835 - val_accuracy: 0.8964\n",
      "Epoch 157/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6568 - accuracy: 0.8213 - val_loss: 0.3851 - val_accuracy: 0.8955\n",
      "Epoch 158/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6565 - accuracy: 0.8206 - val_loss: 0.3839 - val_accuracy: 0.8957\n",
      "Epoch 159/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6553 - accuracy: 0.8213 - val_loss: 0.3821 - val_accuracy: 0.8960\n",
      "Epoch 160/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6545 - accuracy: 0.8211 - val_loss: 0.3824 - val_accuracy: 0.8968\n",
      "Epoch 161/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6551 - accuracy: 0.8221 - val_loss: 0.3818 - val_accuracy: 0.8968\n",
      "Epoch 162/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6528 - accuracy: 0.8215 - val_loss: 0.3812 - val_accuracy: 0.8965\n",
      "Epoch 163/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6539 - accuracy: 0.8217 - val_loss: 0.3837 - val_accuracy: 0.8957\n",
      "Epoch 164/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6534 - accuracy: 0.8216 - val_loss: 0.3812 - val_accuracy: 0.8964\n",
      "Epoch 165/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6536 - accuracy: 0.8221 - val_loss: 0.3817 - val_accuracy: 0.8962\n",
      "Epoch 166/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6520 - accuracy: 0.8221 - val_loss: 0.3814 - val_accuracy: 0.8969\n",
      "Epoch 167/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6535 - accuracy: 0.8218 - val_loss: 0.3796 - val_accuracy: 0.8973\n",
      "Epoch 168/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6527 - accuracy: 0.8214 - val_loss: 0.3821 - val_accuracy: 0.8967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6525 - accuracy: 0.8219 - val_loss: 0.3828 - val_accuracy: 0.8958\n",
      "Epoch 170/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6523 - accuracy: 0.8227 - val_loss: 0.3807 - val_accuracy: 0.8971\n",
      "Epoch 171/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6543 - accuracy: 0.8217 - val_loss: 0.3813 - val_accuracy: 0.8971\n",
      "Epoch 172/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6522 - accuracy: 0.8227 - val_loss: 0.3815 - val_accuracy: 0.8973\n",
      "Epoch 173/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6521 - accuracy: 0.8221 - val_loss: 0.3817 - val_accuracy: 0.8968\n",
      "Epoch 174/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6523 - accuracy: 0.8222 - val_loss: 0.3808 - val_accuracy: 0.8973\n",
      "Epoch 175/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6519 - accuracy: 0.8225 - val_loss: 0.3816 - val_accuracy: 0.8968\n",
      "Epoch 176/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6509 - accuracy: 0.8228 - val_loss: 0.3795 - val_accuracy: 0.8970\n",
      "Epoch 177/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6519 - accuracy: 0.8224 - val_loss: 0.3809 - val_accuracy: 0.8970\n",
      "Epoch 178/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6500 - accuracy: 0.8227 - val_loss: 0.3804 - val_accuracy: 0.8968\n",
      "Epoch 179/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6505 - accuracy: 0.8231 - val_loss: 0.3802 - val_accuracy: 0.8972\n",
      "Epoch 180/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6505 - accuracy: 0.8228 - val_loss: 0.3798 - val_accuracy: 0.8972\n",
      "Epoch 181/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6501 - accuracy: 0.8229 - val_loss: 0.3784 - val_accuracy: 0.8977\n",
      "Epoch 182/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6496 - accuracy: 0.8225 - val_loss: 0.3788 - val_accuracy: 0.8974\n",
      "Epoch 183/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6492 - accuracy: 0.8233 - val_loss: 0.3816 - val_accuracy: 0.8968\n",
      "Epoch 184/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6506 - accuracy: 0.8227 - val_loss: 0.3797 - val_accuracy: 0.8974\n",
      "Epoch 185/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6484 - accuracy: 0.8232 - val_loss: 0.3795 - val_accuracy: 0.8972\n",
      "Epoch 186/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6492 - accuracy: 0.8230 - val_loss: 0.3780 - val_accuracy: 0.8974\n",
      "Epoch 187/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6484 - accuracy: 0.8229 - val_loss: 0.3792 - val_accuracy: 0.8980\n",
      "Epoch 188/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6503 - accuracy: 0.8228 - val_loss: 0.3793 - val_accuracy: 0.8974\n",
      "Epoch 189/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6493 - accuracy: 0.8234 - val_loss: 0.3792 - val_accuracy: 0.8972\n",
      "Epoch 190/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6491 - accuracy: 0.8225 - val_loss: 0.3785 - val_accuracy: 0.8975\n",
      "Epoch 191/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6486 - accuracy: 0.8233 - val_loss: 0.3792 - val_accuracy: 0.8971\n",
      "Epoch 192/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6473 - accuracy: 0.8233 - val_loss: 0.3774 - val_accuracy: 0.8980\n",
      "Epoch 193/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6491 - accuracy: 0.8233 - val_loss: 0.3773 - val_accuracy: 0.8977\n",
      "Epoch 194/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6486 - accuracy: 0.8230 - val_loss: 0.3788 - val_accuracy: 0.8972\n",
      "Epoch 195/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6464 - accuracy: 0.8238 - val_loss: 0.3798 - val_accuracy: 0.8965\n",
      "Epoch 196/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6476 - accuracy: 0.8237 - val_loss: 0.3829 - val_accuracy: 0.8960\n",
      "Epoch 197/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6476 - accuracy: 0.8230 - val_loss: 0.3817 - val_accuracy: 0.8967\n",
      "Epoch 198/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6477 - accuracy: 0.8242 - val_loss: 0.3801 - val_accuracy: 0.8970\n",
      "Epoch 199/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6482 - accuracy: 0.8237 - val_loss: 0.3780 - val_accuracy: 0.8974\n",
      "Epoch 200/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6468 - accuracy: 0.8235 - val_loss: 0.3778 - val_accuracy: 0.8977\n",
      "Epoch 201/300\n",
      "1697/1697 [==============================] - 7s 4ms/step - loss: 0.6470 - accuracy: 0.8240 - val_loss: 0.3780 - val_accuracy: 0.8977\n",
      "Epoch 202/300\n",
      "1697/1697 [==============================] - 6s 3ms/step - loss: 0.6468 - accuracy: 0.8235 - val_loss: 0.3793 - val_accuracy: 0.8974\n",
      "Epoch 203/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6492 - accuracy: 0.8226 - val_loss: 0.3772 - val_accuracy: 0.8982\n",
      "Epoch 204/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6470 - accuracy: 0.8237 - val_loss: 0.3787 - val_accuracy: 0.8971\n",
      "Epoch 205/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6463 - accuracy: 0.8239 - val_loss: 0.3791 - val_accuracy: 0.8966\n",
      "Epoch 206/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6456 - accuracy: 0.8243 - val_loss: 0.3779 - val_accuracy: 0.8975\n",
      "Epoch 207/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6459 - accuracy: 0.8236 - val_loss: 0.3764 - val_accuracy: 0.8978\n",
      "Epoch 208/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6468 - accuracy: 0.8241 - val_loss: 0.3767 - val_accuracy: 0.8975\n",
      "Epoch 209/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6470 - accuracy: 0.8232 - val_loss: 0.3794 - val_accuracy: 0.8966\n",
      "Epoch 210/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6456 - accuracy: 0.8241 - val_loss: 0.3782 - val_accuracy: 0.8972\n",
      "Epoch 211/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6463 - accuracy: 0.8238 - val_loss: 0.3762 - val_accuracy: 0.8980\n",
      "Epoch 212/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6448 - accuracy: 0.8243 - val_loss: 0.3803 - val_accuracy: 0.8968\n",
      "Epoch 213/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6458 - accuracy: 0.8240 - val_loss: 0.3771 - val_accuracy: 0.8978\n",
      "Epoch 214/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6439 - accuracy: 0.8248 - val_loss: 0.3777 - val_accuracy: 0.8976\n",
      "Epoch 215/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6464 - accuracy: 0.8238 - val_loss: 0.3763 - val_accuracy: 0.8980\n",
      "Epoch 216/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6466 - accuracy: 0.8235 - val_loss: 0.3760 - val_accuracy: 0.8985\n",
      "Epoch 217/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6452 - accuracy: 0.8238 - val_loss: 0.3762 - val_accuracy: 0.8979\n",
      "Epoch 218/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6468 - accuracy: 0.8239 - val_loss: 0.3766 - val_accuracy: 0.8982\n",
      "Epoch 219/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6438 - accuracy: 0.8243 - val_loss: 0.3759 - val_accuracy: 0.8979\n",
      "Epoch 220/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6447 - accuracy: 0.8250 - val_loss: 0.3786 - val_accuracy: 0.8969\n",
      "Epoch 221/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6454 - accuracy: 0.8242 - val_loss: 0.3765 - val_accuracy: 0.8981\n",
      "Epoch 222/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6443 - accuracy: 0.8241 - val_loss: 0.3752 - val_accuracy: 0.8981\n",
      "Epoch 223/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6443 - accuracy: 0.8244 - val_loss: 0.3752 - val_accuracy: 0.8985\n",
      "Epoch 224/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6430 - accuracy: 0.8251 - val_loss: 0.3770 - val_accuracy: 0.8980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6435 - accuracy: 0.8244 - val_loss: 0.3750 - val_accuracy: 0.8985\n",
      "Epoch 226/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6449 - accuracy: 0.8248 - val_loss: 0.3746 - val_accuracy: 0.8987\n",
      "Epoch 227/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6432 - accuracy: 0.8250 - val_loss: 0.3764 - val_accuracy: 0.8984\n",
      "Epoch 228/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6421 - accuracy: 0.8254 - val_loss: 0.3757 - val_accuracy: 0.8986\n",
      "Epoch 229/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6437 - accuracy: 0.8248 - val_loss: 0.3741 - val_accuracy: 0.8985\n",
      "Epoch 230/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6439 - accuracy: 0.8244 - val_loss: 0.3747 - val_accuracy: 0.8984\n",
      "Epoch 231/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6441 - accuracy: 0.8244 - val_loss: 0.3741 - val_accuracy: 0.8982\n",
      "Epoch 232/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6409 - accuracy: 0.8250 - val_loss: 0.3731 - val_accuracy: 0.8987\n",
      "Epoch 233/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6418 - accuracy: 0.8245 - val_loss: 0.3742 - val_accuracy: 0.8990\n",
      "Epoch 234/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6418 - accuracy: 0.8248 - val_loss: 0.3736 - val_accuracy: 0.8988\n",
      "Epoch 235/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6420 - accuracy: 0.8244 - val_loss: 0.3759 - val_accuracy: 0.8981\n",
      "Epoch 236/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6421 - accuracy: 0.8253 - val_loss: 0.3735 - val_accuracy: 0.8989\n",
      "Epoch 237/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6435 - accuracy: 0.8244 - val_loss: 0.3757 - val_accuracy: 0.8983\n",
      "Epoch 238/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6437 - accuracy: 0.8250 - val_loss: 0.3778 - val_accuracy: 0.8973\n",
      "Epoch 239/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6409 - accuracy: 0.8255 - val_loss: 0.3742 - val_accuracy: 0.8985\n",
      "Epoch 240/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6408 - accuracy: 0.8253 - val_loss: 0.3756 - val_accuracy: 0.8978\n",
      "Epoch 241/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6422 - accuracy: 0.8253 - val_loss: 0.3759 - val_accuracy: 0.8982\n",
      "Epoch 242/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6417 - accuracy: 0.8253 - val_loss: 0.3739 - val_accuracy: 0.8986\n",
      "Epoch 243/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6417 - accuracy: 0.8248 - val_loss: 0.3743 - val_accuracy: 0.8982\n",
      "Epoch 244/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6411 - accuracy: 0.8256 - val_loss: 0.3765 - val_accuracy: 0.8978\n",
      "Epoch 245/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6403 - accuracy: 0.8258 - val_loss: 0.3738 - val_accuracy: 0.8986\n",
      "Epoch 246/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6406 - accuracy: 0.8254 - val_loss: 0.3777 - val_accuracy: 0.8972\n",
      "Epoch 247/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6413 - accuracy: 0.8253 - val_loss: 0.3757 - val_accuracy: 0.8982\n",
      "Epoch 248/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6394 - accuracy: 0.8264 - val_loss: 0.3742 - val_accuracy: 0.8991\n",
      "Epoch 249/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6396 - accuracy: 0.8260 - val_loss: 0.3730 - val_accuracy: 0.8986\n",
      "Epoch 250/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6404 - accuracy: 0.8253 - val_loss: 0.3750 - val_accuracy: 0.8983\n",
      "Epoch 251/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6412 - accuracy: 0.8251 - val_loss: 0.3753 - val_accuracy: 0.8982\n",
      "Epoch 252/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6399 - accuracy: 0.8261 - val_loss: 0.3748 - val_accuracy: 0.8984\n",
      "Epoch 253/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6413 - accuracy: 0.8258 - val_loss: 0.3746 - val_accuracy: 0.8984\n",
      "Epoch 254/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6405 - accuracy: 0.8257 - val_loss: 0.3733 - val_accuracy: 0.8984\n",
      "Epoch 255/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6395 - accuracy: 0.8258 - val_loss: 0.3731 - val_accuracy: 0.8988\n",
      "Epoch 256/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6397 - accuracy: 0.8257 - val_loss: 0.3744 - val_accuracy: 0.8980\n",
      "Epoch 257/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6406 - accuracy: 0.8253 - val_loss: 0.3725 - val_accuracy: 0.8989\n",
      "Epoch 258/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6411 - accuracy: 0.8258 - val_loss: 0.3744 - val_accuracy: 0.8982\n",
      "Epoch 259/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6398 - accuracy: 0.8248 - val_loss: 0.3742 - val_accuracy: 0.8987\n",
      "Epoch 260/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6388 - accuracy: 0.8259 - val_loss: 0.3732 - val_accuracy: 0.8987\n",
      "Epoch 261/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6390 - accuracy: 0.8256 - val_loss: 0.3745 - val_accuracy: 0.8985\n",
      "Epoch 262/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6414 - accuracy: 0.8257 - val_loss: 0.3772 - val_accuracy: 0.8973\n",
      "Epoch 263/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6403 - accuracy: 0.8254 - val_loss: 0.3742 - val_accuracy: 0.8989\n",
      "Epoch 264/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6422 - accuracy: 0.8252 - val_loss: 0.3758 - val_accuracy: 0.8979\n",
      "Epoch 265/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6390 - accuracy: 0.8263 - val_loss: 0.3732 - val_accuracy: 0.8988\n",
      "Epoch 266/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6400 - accuracy: 0.8256 - val_loss: 0.3732 - val_accuracy: 0.8993\n",
      "Epoch 267/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6385 - accuracy: 0.8265 - val_loss: 0.3723 - val_accuracy: 0.8991\n",
      "Epoch 268/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6386 - accuracy: 0.8258 - val_loss: 0.3734 - val_accuracy: 0.8982\n",
      "Epoch 269/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6383 - accuracy: 0.8259 - val_loss: 0.3739 - val_accuracy: 0.8985\n",
      "Epoch 270/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6400 - accuracy: 0.8257 - val_loss: 0.3727 - val_accuracy: 0.8988\n",
      "Epoch 271/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6369 - accuracy: 0.8263 - val_loss: 0.3750 - val_accuracy: 0.8978\n",
      "Epoch 272/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6398 - accuracy: 0.8258 - val_loss: 0.3732 - val_accuracy: 0.8984\n",
      "Epoch 273/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6380 - accuracy: 0.8262 - val_loss: 0.3735 - val_accuracy: 0.8983\n",
      "Epoch 274/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6365 - accuracy: 0.8267 - val_loss: 0.3727 - val_accuracy: 0.8989\n",
      "Epoch 275/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6361 - accuracy: 0.8266 - val_loss: 0.3738 - val_accuracy: 0.8987\n",
      "Epoch 276/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6395 - accuracy: 0.8260 - val_loss: 0.3736 - val_accuracy: 0.8985\n",
      "Epoch 277/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6391 - accuracy: 0.8265 - val_loss: 0.3731 - val_accuracy: 0.8987\n",
      "Epoch 278/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6361 - accuracy: 0.8264 - val_loss: 0.3723 - val_accuracy: 0.8988\n",
      "Epoch 279/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6383 - accuracy: 0.8268 - val_loss: 0.3712 - val_accuracy: 0.8993\n",
      "Epoch 280/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6381 - accuracy: 0.8258 - val_loss: 0.3727 - val_accuracy: 0.8991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6378 - accuracy: 0.8265 - val_loss: 0.3714 - val_accuracy: 0.8994\n",
      "Epoch 282/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6399 - accuracy: 0.8254 - val_loss: 0.3743 - val_accuracy: 0.8978\n",
      "Epoch 283/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6387 - accuracy: 0.8263 - val_loss: 0.3726 - val_accuracy: 0.8986\n",
      "Epoch 284/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6386 - accuracy: 0.8264 - val_loss: 0.3753 - val_accuracy: 0.8974\n",
      "Epoch 285/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6380 - accuracy: 0.8266 - val_loss: 0.3719 - val_accuracy: 0.8991\n",
      "Epoch 286/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6382 - accuracy: 0.8270 - val_loss: 0.3716 - val_accuracy: 0.8993\n",
      "Epoch 287/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6374 - accuracy: 0.8265 - val_loss: 0.3720 - val_accuracy: 0.8989\n",
      "Epoch 288/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6384 - accuracy: 0.8269 - val_loss: 0.3722 - val_accuracy: 0.8989\n",
      "Epoch 289/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6361 - accuracy: 0.8269 - val_loss: 0.3713 - val_accuracy: 0.8994\n",
      "Epoch 290/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6370 - accuracy: 0.8266 - val_loss: 0.3744 - val_accuracy: 0.8985\n",
      "Epoch 291/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6371 - accuracy: 0.8265 - val_loss: 0.3708 - val_accuracy: 0.8990\n",
      "Epoch 292/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6365 - accuracy: 0.8271 - val_loss: 0.3722 - val_accuracy: 0.8989\n",
      "Epoch 293/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6378 - accuracy: 0.8263 - val_loss: 0.3710 - val_accuracy: 0.8997\n",
      "Epoch 294/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6380 - accuracy: 0.8263 - val_loss: 0.3717 - val_accuracy: 0.8990\n",
      "Epoch 295/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6368 - accuracy: 0.8264 - val_loss: 0.3707 - val_accuracy: 0.8990\n",
      "Epoch 296/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6361 - accuracy: 0.8271 - val_loss: 0.3717 - val_accuracy: 0.8989\n",
      "Epoch 297/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6358 - accuracy: 0.8270 - val_loss: 0.3714 - val_accuracy: 0.8997\n",
      "Epoch 298/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6367 - accuracy: 0.8271 - val_loss: 0.3716 - val_accuracy: 0.8992\n",
      "Epoch 299/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6360 - accuracy: 0.8267 - val_loss: 0.3718 - val_accuracy: 0.8988\n",
      "Epoch 300/300\n",
      "1697/1697 [==============================] - 6s 4ms/step - loss: 0.6359 - accuracy: 0.8271 - val_loss: 0.3732 - val_accuracy: 0.8987\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs = N_EPOCHS, validation_data=(X_valid, y_valid), batch_size=264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./trained_models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./trained_models/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./trained_models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-a806faee-b006-45c2-8e7c-472d4464102a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Análise do treinamento\n",
    "Pode-se perceber pelos gráficos 1 e 2 que o modelo apresenta uma melhora na acurácia e no erro a cada iteração. Além disso, a validação acompanha essa melhora do treinamento, ou seja, o modelo apresenta bons resultados para o que ele está sendo treinado e também para dados genéricos(dados que nao estavam presente no treinamento), eliminando a possibilidade de overfitting. Por fim, a acurácia de validação do treinamento e o erro dessa validação são melhores que o próprio treinamento, visto que há duas camadas de dropout durante o treinamento, que eliminam aleatóriamente alguns dados de entrada, mas mantendo a soma total das entradas. Dessa forma, o modelo não se acomoda com os dados de treinamento e é obrigado a ser capaz de generalizar (evitando overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00013-7ef1be91-0b0f-4278-b119-046ea892e352",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAGiCAYAAACWDzX7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAACCTUlEQVR4nO3deXxddZ3/8dfnLtm3Jm3SfS+UpRRKFxQLKLK4QGVRqTqKDjKIOuqMOsjwc9DRkXEYxR1xBUUqLjioMAoDyA4t0AKlFNrS0nRN2uzrXb6/P74n6U2apGmb5uak7+fjcR/Jvffccz7n3uSe+77f5ZhzDhERERERERk5ItkuQERERERERHpSUBMRERERERlhFNRERERERERGGAU1ERERERGREUZBTUREREREZIRRUBMRERERERlhFNSOcmYWN7PVZvaOQS5/r5l9aIi2/ZCZXTEU6zrE7b/fzP6are2PZmY23cycmcWC6/3+3fRe9jC2mWNmL5jZ781skZl94zDX95iZnTLIZZ82sxMOZ3siMjqZ2fVm9sssbn+qmTWbWTRbNYxmZrbZzN4a/H6tmf14MMse5jZ/bGYvmdkUM/u/w1zX18zs04Nc9r/N7GOHsz05OApqI1AQYOrMLHcYNvcF4E/OuT8PZmHn3Nucc7ce4Zr6ZWZLgwNOs5m1BB/wmzMuUwe7Lufc7c65c49kvUNtqELNILf1spl9pI/bP2Vmqw5mXcP0d3MccBfwW+Bm4I5DXZGZXQA0OeeeC66faGZ/MbNaM+vr5JM3Al8+1O2JyJETfDhu63Ws+G626zqQXvWme+3D+we7Hufc6865Iudc6kjWO9SGKtQMYjs3m9ltfdw+38w6zKx8sOtyzv2Hc244voAeC7wf+DVw56GuxMzGAR8EfhhcP83M7jOzvWZWY2a/MbMJGQ+5EbjWzHIOo3Y5CApqI4yZTQeWAg648Ais38wsEvweBeqBLw71do4U59wjwQGnCOhqwSjrus0593rXssMRZka5W/Fv4L39XXDfiOKcW+Oc+6Jz7lfOuVOdcysPY3VXAb/IuJ7AHwz/vp/l7wbebGbjD2ObInLkXJBxnChyzn2ir4X6Om5kqyUqs17gdXruw+0Z9elYd3huBS42s8Jet/8d/ovsvVmoaUDOuXc5555zzr3ROffDw1jV5cA9zrm24PoY4BZgOjANaAJ+lrHdHcDLHIHPp9I3BbWR54PAk8DPgR5dxYIm7t8H33Ls6fpGsHe3ij66nT1kZl81s8eAVmCmmX0YeBH4KrDBzP6h17aWBV0iG81so5mdn7GuK4LfZ5nZA0EttWZ2u5mV9bdjZnZO0ErTENRuve7/iJmtC1oT/2Jm0w7miQueh9+a2S/NrBG43MxKzewnZrbDzLaZ2Ve6DrpmdrmZPZrxeGdmV5nZq2ZWb2bfMzMbzL4G3/x9zsyeD1r6fmJmVea7/DWZ2f1mNiZj+dPM7PFgO2vM7KyM+x4ys3833/Wuycz+amZjg7sfDn7WB9+qvsHMImZ2nZltMbPdZnabmZUO8Dy9M3ht64MaTupn0V8Ab8p8HczseOAk4A4ze4eZPRf8jWw1s+sH2Gbm303UzG4MnsdNwDt6Lfvh4O+gycw2HcTf5oEe91Ez22D+m8K7zWxiP7XmAG8B/tZ1m3NuvXPuJ8Davh7jnGsHngHO6+85EJGRJzgOPGZm3zSzPcD1ZvZzM/uBmd1jZi34L2GOC97H6s1srZn1+0HVzGaY2d+C96L78K0fmff3+/4/yJrPMrNqM/sXM9sJ/Cw4DlwTvCfuMbM7LWgJsr4/E/R3jMF8K8pO88fqhy2jW3fw3Hw/OLY1B+sYb2Y3mT92v2wZXcbNbKKZ/c7855bXzOwfM+67PqjztqCOtWa2MLjvF8BU4I/Bdj4f3H5hsFx9sB/HDfA8zbV9rUPrzew9fS3nnHsC2AZckvHYKPA+4DY7iM86tv/nsb8zf2zeY2b/2mvZxWb2RLAvO8zsu5bRUmVmJ2TUv8vMrh3k495oZiuD12+lmb2xv+cIeBs9j3X3Oud+45xrdM61At8FTu/1mIfoddyWI8g5p8sIugAbgKuBU/Hf4lcFt0eBNcA3gUIgD3hTcN/1wC8z1jEd3yIXC64/hP827gQgBsSBC4BZ+LB0Jj7ALQiWXww0AOfgw/wkYG7Guq4Ifp8dLJMLjMOHiJv62a+x+G9mLg22/xkgmbGuZcG+HxfUeB3w+AGeq977eX3wnL0rqDsf3xXuh8FzVgk8DfxDsPzlwKMZ63PAn4Ay/AGiBjh/MPsKbMYH7Krg+doNPAucErxWDwD/Fiw7CdgDvD2o85zg+riM53gjcEywDw8BN/S1z8FtHwmeu5lAEfB74Bf9PGenBLUtwf9NfSioPbef5e8Drsu4/jXgD8HvZwHzgn04CdgFvGuAv8Gu1/oq/DdyU4By4MFey76DQ/vbHOhxbwFqgQXBa/gd4OF+9vkEoKWf+2YDrp/7vg18I9vvIbrookvPS/Ae99Z+7rscfyz6JP7Yk4//orQB/wE1AhQH77HXAl1f5DQBx/azzieAbwTvNWcEy/4yuG/A9//B7EPw3psE/jPYRj7wKfwxaHJw2w+BO4Ll+3o/7vMYE9z/kWCfc4GbgNUZ9/08eC89lX3HttfwXzJHga8ADwbLRvBfYH0xeN5mApuA84L7rwfag+ciij++PNnf6xbU2xI8Z3Hg88HrktPH81UIbAU+HLyupwR1H9/P8/uvwP0Z18/DfwaIM7jj/1sz9qnrtT4eaA7+BnKDv4lkxrKnAqcF9U0H1gGfDu4rBnYA/xw8z8XAkkE8rhyow7cGxoDlwfWKfva7Blg0wN/dpzNfk+C2i4Fns/1/fbRcsl6ALhkvBrwJHzTGBtdfBj4T/P6G4B8q1sfjut8YguvT2f9N+csH2PYfgE8Fv/8Q+GY/yz1E8IG7j/veBTzXz30fpOcbsAHV7Pvwfi/w9xn3R/AftKcNUHPv/byejA/f+NDUAeRn3LacfQeRy9k/qL0p4/qdwDWD2Vf8G/X7M67/DvhBxvVPsi/g/Au9ghTwF+BDGc9xZji6GvjfvvY5uO3/gKszrh8b/B319bfyA+Dfe922Hjizn/38ALA+4zV5Hbion2Vv6vq76edvsOu1fgC4KuNx5/bep0P52zzA434CfD3jvqLgOZrex+NOB3b2s86BgtpXgZ8OpjZddNFl+C7B+3Mzvqt/1+WjwX2XA6/3Wv7nwG0Z15cCO4FIxm13ANf3sa2p+A/jhRm3/Yp9H94HfP8/wD5kBrVOIC/j/nXA2RnXJ3QdB/p5P+7zGNPHdsuCx5ZmPDc/yrj/k8C6jOvzgPrg9yV9PLdfAH4W/H49PcPR8UBbX/scXP9/wJ0Z1yP4lrCz+qj7vcAjvW77IcEXpv28bglgcnD9duBb/Sz7LvY//vcV1L4IrMhYrjB43fr70uDTwF3B78vp5/PUAR73d8DTve5/Ari8n8cmCL7s7OO+k4C9wNJet58DbBpMbboc/kX9mkeWDwF/dc7VBtd/Fdz2TXzrwxbnXPIQ170184qZnY1/05sJpPEtXi8Ed08B7jnQCs2sCvgW/iBWjH/TrOtn8YmZNTjnnJll1jQN+JaZ/XfmJvDfPm45UC0Zeq8zDuww6+5lGem1TG87M35vxX+gH+y+7sr4va2P60UZdb3b/IQVXeL4lqUB6+jHRHo+R1vwB+cq/EEs0zTgQ2b2yYzbcoJ19OX3wPfN7DSgILj8GcDMlgA3ACcG68gFfjNAnZn1Zr4GPV5fM3sb8G/4b08jwTYP+Ld5gMdNxLdwAuCcazbfzWkS/iCbqQ7/Gh+sYvwHQBEZed7lnLu/n/v6OiZk3jYR2OqcS2fctgX//tHbRKDOOdfSa9kpwe+Def8fjBrnu1x3mQbcZWaZNabwx4G+9Hesi+K/dHo3vvWoa31j8a2McHDHuolmVp9xfxR4ZIA68sws1s9nnR7HOudcOvgc0dfrMA1Y0mvbMXqOPe7mnHvdzB4GPmB+aMa78C1hB/tZp3e9mZ97WoLjDsF6j8G3si3EH69i+BZI8H8vG/ta6QEe1/vzAPT/twr9HO/MbDb+C/RPOece6XW3jnXDSGPURggzywfeA5wZ9A3fie8eON/M5uP/2ada34OGW/D/rF36mtDAZWwrB/gf4L/xLVbT8a0yXWlmK74L2YH8R7Deec65Enzri/Wz7A72Hagwn5ymZNy/Fd8lsSzjku+ce3wQdWRyGb9vxbeojc1YZ4lz7lCmUT+YfT2QrfhvVDP3tdA5d8MgHuv6uG07/qDUpesb3V19LLsV+GqvbRc45/qcIdH5Puq/xbeI/h3+28HO4O5f4SfRmOKcK8XPtDiY56TH30JQLwDmZzr9HX5mqSrnXBk+mA34tzmIx/V4jswPGq9g/yALviuNmVl/B7b+HIfvniwi4dLX+2rmbduBKRZMxBWYSt/vHzuAMdZzYorM2YgP5/1/oJq3Am/rtd4851xfNQ7kffihCG8FSvGtcXBox7utwGu9aip2zr19kI/vvY+938e7Pkf0tY9bgb/12naRc26gqeVvxR/nLgnq7go/h3r87/25pwB/3OnyA3zPqTnBeq+l57FuZj/rHehxvT8PQP9/qwDP47/c7GZ+XPr9+N43fQVbHeuGkYLayPEu/LdfxwMnB5fj8N88fRA/tmoHcIOZFZpZnpl1DfBcDZxh/lwppfiuBQPp6tPeAt0tEedk3P8T4MNmdrb5AcqTzGxuH+spxncnaQg+1H5ugG3+GTjBzC4OwuY/0jNQ3gx8wYJBy+YnAXn3AfZjQM7PTvRX4L/NrCTYl1lmduYhrO5g9vVAfglcYGbnmZ9YI8/84PDJg3hsDf4bzsw38DuAz5gfwF6EP6j8up9vJH8EXGVmS8wrND8pyEAtSLfiu5FcQs/ZHouBvc65djNbjD/AD8adwD+a2WTzE6xck3FfV8tcDZAM/jYzT6HQ39/mgR53R/C4k4NQ9x/AU865zb2LC4Lo/fhxbkD3bKl5wXYIXrPcjPvz8OMG7hvkcyAi4fEUvrXn8+bPPXoWfpz3it4LOue2AKuAL5k/t+ObgmW7HM77/0BuBr4afMjGzMaZ2bJDWE8x/gvOPfgvgP/jMGp6GmgyP+lJfrC/J5rZokE+fhc9j3V3Au8I3v/j+PFbHUBfX+j+CTjG/GQe8eCyyAaYfAT/Zd9U4Evsf6w7lOP/b4F3mtmbgi/Iv0zPz93FQCPQHBzHMkPkn4AJZvZpM8s1s2LzvVgO9Lh7gv1+n5nFzOy9+M+Vf+qnxnvoeaybhB+e8F3n3M39POZMfGubDAMFtZHjQ/h+268753Z2XfAz7rwf/23JBfgxMq/jx3e9F8A5dx/+XBrP45u/+/uHJFi+CR+U7sA3e78P3zLSdf/T+AG438R3dfgb+39DA/7NbEGwzJ/x3eT622YtvivFDfgDwBzgsYz778IPjF5hfsbGF/GzER2uD+I/XL+E39ff4vvuH6xB7+uBOOe24r+xvBYfLLbi3/gP+P8YtHB9FXjM/IxPpwE/xXfneBg/qLsdP26gr8evAj6K/7uqw7ceXX6AzT6M3+9q13PK+6uBL5tZE74v/mDP5fIj/JiMNfjuiN3PZcbf5p0c+G8zRfC3OYjH3Y/v6vs7/Bces4DLBqjxh/hvVrtMw3fp6Zr1sQ0/tq/LBcBDzrntg9h/ERl+XbMHdl3uGuwDgy9vLsAfk2qB7wMfdM693M9D3ocfn7UX3x27+xxdh/P+fwDfwr/n/TV4T34yqOFg3YbvKrcNf9x88lALcv68be/Ef/H8Gv65+zG+pW4wvgZcFxzrPuucW49vzfpOsK4L8Kcs6Oz9wOCYcC7+fX47votl1+Qr/dXbgj9GTMaPUetySMd/59xa4OP43ic78Mem6oxFPov/W2nCHxd/3av+c4J9bMe/Hm8exOP24J/zf8Z/1vo88M6MITW93Qa83XyvLoAr8OH4+sz/l66FzZ9T7Xj8GHAZBuZcXy3+IiIjm5n9P/zMoP93hNb/GPAJF5z0+gDLPoWfDOfFI1GLiIgcncxsKXCuc+7/HaH1/wew2zl30yCW/W9go3Pu+0eiFtmfgpqIhE7QxfMSfB/967Jdj4iIyFALjnUVwO3OuTdlux4Zfur6KCJh9AC+++MD2S5ERETkCPkSvgvqgENaZPRSi5qIiIiIiMgIoxY1ERERERGREUZBTUREREREZITp6+TJw2Ls2LFu+vTp2dq8iIgMo2eeeabWOTcu23WEhY6RIiJHh4GOj1kLatOnT2fVqlXZ2ryIiAwjM9uS7RrCRMdIEZGjw0DHR3V9FBERERERGWEU1EREREREREYYBTUREREREZERJmtj1ERERERE5MhLJBJUV1fT3t6e7VKOWnl5eUyePJl4PD7oxyioiYiIiIiMYtXV1RQXFzN9+nTMLNvlHHWcc+zZs4fq6mpmzJgx6Mep66OIiIiIyCjW3t5ORUWFQlqWmBkVFRUH3aKpoCYiIiIiMsoppGXXoTz/CmoiIiIiInLE7Nmzh5NPPpmTTz6Z8ePHM2nSpO7rnZ2dAz725ptv5rbbbhumSgenvr6e73//+0d8OxqjJiIiIiIiR0xFRQWrV68G4Prrr6eoqIjPfvaz3fcnk0lisb5jyVVXXTUcJR6UrqB29dVXH9HtqEVNRERERESG1eWXX85VV13FkiVL+PznP8/GjRs5//zzOfXUU1m6dCkvv/wy4IPdjTfeCMBZZ53Fv/zLv7B48WKOOeYYHnnkEQA2b97M0qVLWbBgAQsWLODxxx8H4KGHHuLMM89k2bJlzJw5k2uuuYbbb7+dxYsXM2/ePDZu3AhATU0Nl1xyCYsWLWLRokU89thj3dv+yEc+wllnncXMmTP59re/DcA111zDxo0bOfnkk/nc5z6Hc47Pfe5znHjiicybN49f//rXQ/IcqUVNRERERESGXXV1NY8//jjRaJSzzz6bm2++mTlz5vDUU09x9dVX88ADD+z3mGQyydNPP80999zDl770Je6//34qKyu57777yMvL49VXX2X58uWsWrUKgDVr1rBu3TrKy8uZOXMmV1xxBU8//TTf+ta3+M53vsNNN93Epz71KT7zmc/wpje9iddff53zzjuPdevWAfDyyy/z4IMP0tTUxLHHHsvHPvYxbrjhBl588cXuVsLf/e53rF69mjVr1lBbW8uiRYs444wzmDBhwmE9P4MKamZ2PvAtIAr82Dl3Q6/7pwE/BcYBe4EPOOeqD6syEREREREZUl/641pe2t44pOs8fmIJ/3bBCQf9uHe/+91Eo1Gam5t5/PHHefe73919X0dHR5+PufjiiwE49dRT2bx5M+DPE/eJT3yC1atXE41GeeWVV7qXX7RoUXdgmjVrFueeey4A8+bN48EHHwTg/vvv56WXXup+TGNjI83NzQC84x3vIDc3l9zcXCorK9m1a9d+NT366KMsX76caDRKVVUVZ555JitXruTCCy886Ock0wGDmplFge8B5wDVwEozu9s591LGYjcCtznnbjWztwBfA/7usCoTEREREZFRq7CwEIB0Ok1ZWVl3C9VAcnNzAYhGoySTSQC++c1vUlVVxZo1a0in0+Tl5e23PEAkEum+HolEuh+fTqd58sknezyur8dnbnM4DKZFbTGwwTm3CcDMVgDLgMygdjzwT8HvDwJ/GMIaRURERERkCBxKy9eRVlJSwowZM/jNb37Du9/9bpxzPP/888yfP39Qj29oaGDy5MlEIhFuvfVWUqnUQW3/3HPP5Tvf+Q6f+9znAFi9ejUnn3xyv8sXFxfT1NTUfX3p0qX88Ic/5EMf+hB79+7l4Ycf5r/+678Oqoa+DCaoTQK2ZlyvBpb0WmYNcDG+e+RFQLGZVTjn9hx2hSJydEqnwDmI9vM2lU6DS0E0Dq17oa0O8koh2QE4/3tOkV+2YSvUBN0gxp8IkRg0boOqEyES9dvpOr9Joh1SHf7xAB1Nfj1msPNFqH8dqk6Asqn+tmQnpBN+2ebd4NJQOhl2vgCVx0NHIyRaIZoLhWPBolDzMoybC3s3wpbH/DrGz4Npb4SmndC0A8af5PfdOdi7CRqq/ePzyiDZDu31sO1Z/ztAJA4LP+y3H8+H1x6Bbc/438umQaLFr2fGmf65SrRC9SpoqYGZZ0FOoX/uXnvY7++Ek6B8FuQWQ+Vx+54fCYV/vnMNU8sL+NRb52S7FBGRQbn99tv52Mc+xle+8hUSiQSXXXbZoIPa1VdfzSWXXMJtt93G+eef391SN1jf/va3+fjHP85JJ51EMpnkjDPO4Oabb+53+YqKCk4//XROPPFE3va2t/H1r3+dJ554gvnz52NmfP3rX2f8+PEHVUNfzDk38AJmlwLnO+euCK7/HbDEOfeJjGUmAt8FZgAPA5cAJzrn6nut60rgSoCpU6eeumXLlsPeAZFRKZ2Cus3+99LJENvX7E57I2x9Gpp3wpQlMHYObH8Odr/sQ0UsF8ZM9x/sx0z3QSbRCrF8SHX6oNG21y9fVAlTFvt1ttb6D/W1r8KO5/0H9bJpftlojv9wX73Sb2/8STDtdB9YUgkfOOq3QsPrfruN2yG3BHathVgOLL4Siqpg/b1Qu96HjTnnQPFEeOFOHyDmvhM2PeTrrd8KO5/3IaV8JnQ2w5hpfplX/uKfm+bdkGyD/HJo2d3382hRX3uyLeO2iL+kk1AwFma/FdbdDaVT/O21r/gAWDQe8sdAzTqYfY5/Drc8tm89sXwf+Dqb9t9uvNAHI4v6dXXJH+O3s/N5HwTbG3o+LprrQyL45ybZ5pdx6cH81UBBBbTugQnzYceaAy8fiUNukX9tu+SV+tc00brv+fri3sMOamb2jHNu4WGt5CiycOFC1zUQ/lC89Rt/49iqYr73/gVDWJWIhNW6des47rjjsl3GUa+v12Gg4+NgWtS2AVMyrk8ObuvmnNuOb1HDzIqAS3qHtGC5W4BbwB+EBrFtkaHhHCTaIKeg5+2phG9tieX5YJFb5ENL4zYffvZs9LfNPCto1djmP3gXjPWtDM274ZV7/Qfzkgnw0t3+Q3XFbH89musfP2YGbH4E9mzwH6bBt5wUj/cfxHes8aGrbKoPUlufguZgsKpFYcbSIGDV+zDW1YIDUDEH9rx68M9J4Tj/AT3dq691LM+39qz8SRAaDHA+lEw8Bdb/Lzz3S79s0Xj/gb4jY1ByJA7FE3yLT+kUv40V7wvui/nw2LoXnvuFvy2a4wPMhvuhsBLieT6kLPiQf67rtvhWnZ3Pw72f93VPX+qfx5xC/xpUHudDZ1u9D4YW9c9re4NvcaqY5fcJ82Ew1QnjjoW1d/mgOPedPgxGc2DuO/z2atb7lq0ZS+HZX/jtnvsVmLwYdq/1fxvpFBSU7wvSeaXQ2ervn34G7H7Jv8Z5ZT50rfujbwV7y//zIXbyIjj2bX57r/7VB+SKWb5F66U/+Ba0oir/fI471j9v7fU+JHa1dBWU+zpefxKevc0H2rV3wcK/h7f+m/+7b9y273XZ+ACUTPTPefEEX/PeTf5vyjm/HYv4v9X61/3j1ZoWOhGDVFqHWRGRMBtMi1oMeAU4Gx/QVgLvc86tzVhmLLDXOZc2s68CKefcFwda7+F+WyijTKLNf1jsaPYfTpt3+w/cOcX+g35nk//wHYn6Zbc/5z+cvvY3f33cXP/hs2mH/8BaMsl/iK1/3V+ad/kwMXmx/2DbvAsmLvAtJLuD4ZYW9R+aN9y/rzuZRQ7cmpFXCqmkb0EZN9d/MK/d4Ft5Up37losX+PubdvgPxGVT/H7mFPkPxxsf8NstnQJVx8Oss32wqXkZXvlf37I2ZoYPfrPe4kPSxv+Dl/7HB5dT3u/DZls91G/2rWH1W8Dhw0+yHTDfQpVX6p+HRLtvJcstCrrHtfr1RmM+xLY3+kCQbNsXSpzzH/w3PQQbH/StcDPO9AGhdLIPFpHovv1OdvjXpGmnb0XrChav/tW/djPP8uvYvhomnepf97445wNt+UzIKzmEP7J+ZHZ77E+yw78Wmft1qNJpiBx9p7BUi9rBOdxj5Pk3PczU8gJu+aCechFRi9pIMeQtas65pJl9AvgLfnr+nzrn1prZl4FVzrm7gbOAr5mZw3d9/Pjh7YYMuwN9WO1o9i0AkRg0VvuWpQknwZYnYMYZPjDE832r0ObH/If40sn+g/9rD8PEk/2H8M2P+cAw/zJ4+ke+dSCd8j8PReUJvuVqy+O+K2D+GJh6GjTXwIu/9a0glcf72/LH+GBWtwXyy2DVT31gedt/+e52O9bA6l/5sHbcBT48VZ7gu/NtfdqHrDHT/HPQvMsv75xf1qLQtN23BGV+CHfOB82al313wdyi/vclnQq65fXxOpz77/3s/1x4Q69/t8KxMHa2/33sAcanxPN8i1G38n2/RuNQGLT+ZYYnM//anvIBfzmQWC7MPLPnbZEgFGea9oaB12Pm/46G2mBaizK7nh6uozCkjVZmNgW4DajCfyVyi3PuW72WOQv4H+C14KbfO+e+fKRri5ihBjURkXAb1HnUnHP3APf0uu2LGb//Fvjt0JYmQyLZGYSEef76zheCCQYK/IfvDf/nJxN47WEfWipm+651yXbfRa1us1925/P7d5Hr8iB0d4/rMn4ebN7sW2Zmn+2389ojMGmBH0Pzv9f4iRxmnuXDSVFl0OWr2I+VKqr0LTodzT5U5Zb4bnDplP+QP2G+76YWjR/6c9NQ7bv5FY7dd9sFN+2/3Jjp/pKpfKa/ZCqdvP9jzXwL0rQ3HrieoWitEZHhlAT+2Tn3rJkVA8+Y2X29Tl8D8Ihz7p3DWVgkAukD9JgREZGRbVBBTUawVNKPh2nd4wNPJAaNO2Dt7333tPYGH7bmnOe7ANas6/n4/DG+1emk9/ruXbWv+K5uhWNh72s+PHU0+VabqW/0YSmn0Hct3L4aJi+EV++DqUt8mKp7zXfd692Skwi6zuUW+XE2G+6H45cNbUvFweorWImIDJJzbgewI/i9yczW4WdK7h3Uhl3UTEFNRCTkFNTCYO8m3xJ2zNtg+7M+OG180M+et/OFfZNOZCoc58doxfL941b91LdCvfMmP76pdY8PcTPOOPSWnK4wtuTKfbeVz+h72Xj+vt8LyuGk9xzaNkVERiAzmw6cAjzVx91vMLM1wHbgs5ljvI9gPer6KCIScgpq2dbZsm9ijEmn+pnw8st9V8TXHvaBKtEKOH97217/uGiOnxp96mlw3IV+9jbw3RMLx/qZADPHFZ3/tZ5jccZMG7ZdFBEZzYLZjn8HfNo519jr7meBac65ZjN7O/AHoM/Bo71OYXNYNUUMDjRZmIjIcHnzm9/MNddcw3nnndd920033cT69ev5wQ9+sN/yZ511FjfeeCMLFy7k7W9/O7/61a8oKyvrscz1119PUVERn/3sZw+6nptuuokVK1YwZcoUvvjFLzJv3ryDXsdwUFA7kroOkl0BKZ3yM9+VTISVP/az9b3+5L6p1rvOgQR+JsA55/guhnllfobAp38E86/1Y7vGHrNvoofB0PTaIiJDzszi+JB2u3Pu973vzwxuzrl7zOz7ZjbWOVfbx7JDdgqbiJmm5xeREWP58uWsWLGiR1BbsWIFX//61w/42HvuueeAyxysT3/603z6058e8vUONQW1I6WtDm690J+LKRLzQcmi0NHgJ6HYu8kHrtM+5qdW3/UCPHMrXPhdP4th1xTqmeZflp19ERGR/ZiZAT8B1jnnvtHPMuOBXc45Z2aLgQiw50jXFolojJqIjByXXnop1113HZ2dneTk5LB582a2b9/OHXfcwT/90z/R1tbGpZdeype+9KX9Hjt9+nRWrVrF2LFj+epXv8qtt95KZWUlU6ZM4dRTTwXgRz/6EbfccgudnZ3Mnj2bX/ziFxQUFLBr1y6uuuoqNm3ahJnx4x//mLlz57Js2TLq6upIJBJ85StfYdmyZQB84xvf4Kc//SkAV1xxRdbDnILaUNj5oj8HVmeLn0lwzHQ/WcbudbDo731Ac2l/LqrCcT6QveU6WPrZfS1dx5wLS/85q7shIiIH5XTg74AXzGx1cNu1wFQA59zNwKXAx8wsCbQBl7lh6JMYMTRGTURGjPLychYvXsy9997LsmXLWLFiBe95z3u49tprKS8vJ5VKcfbZZ/P8889z0kkn9bmOZ555hhUrVrB69WqSySQLFizoDmoXX3wxH/3oRwG47rrr+MlPfsInP/lJ/vEf/5G3vOUt3HXXXSSTSVpbW8nLy+Ouu+6ipKSE2tpaTjvtNC688EKeffZZfvazn/HUU0/hnGPJkiWceeaZnHLKKcP2PPWmoHYo0ik/xf26P/rg9fB/+ZMpY358WEuN77p44bfh5Pft//i3XDfsJYuIyNByzj2KPzfJQMt8F/ju8FS0T8SMZCo93JsVkTC49xo/Gd1QGj8P3nbDgIt0dX/sCmo/+clPuPPOO7nllltIJpPs2LGDl156qd+g9sgjj3DRRRdRUFAAwIUXXth934svvsh1111HfX09zc3N3V0sH3jgAX7xi18AEIvFKCkpIZFIcO211/Lwww8TiUTYtm0bu3bt4tFHH+Wiiy6isLAQ8OHvkUceUVALhda9sO7u4Hxgf/MzJlrEt5QVT4QrH/Jjz+L50Nnqf2pcmIiIZEFUXR9FZIRZtmwZn/nMZ3j22WdpbW2lvLycG2+8kZUrVzJmzBguv/xy2tvbD2ndl19+OX/4wx+YP38+P//5z3nooYf6Xfb222+npqaGZ555hng8zvTp0w95u0eagtqBJNrghd/C/df7EzGXTPKzLM4403dXrFkPxeOhLGOGrpyCrJUrIiKi6flFpF8HaPk6UoqKinjzm9/MRz7yEZYvX05jYyOFhYWUlpaya9cu7r33Xs4666x+H3/GGWdw+eWX84UvfIFkMskf//hH/uEf/gGApqYmJkyYQCKR4Pbbb2fSpEkAnH322fzwhz/kk5/8ZHfXx4aGBiorK4nH4zz44INs2bIFgKVLl3L55ZdzzTXX4Jzjrrvu6m6NyxYFtf50tsLfboBnb/MTg0w8Bd5/J0xc0LOlbMri7NUoIiLSB03PLyIj0fLly7noootYsWIFc+fO5ZRTTmHu3LlMmTKF008/fcDHLliwgPe+973Mnz+fyspKFi1a1H3fv//7v7NkyRLGjRvHkiVLaGpqAuBb3/oWH/3oR7nhhhuoqKjgZz/7Ge9///u54IILmDdvHgsXLmTu3Lnd67/88stZvNh/tr/iiiuy2u0RwLL1Rr5w4UK3atWqrGx7QPWv+2nz16yAXWvh+Ath4d/7E0OrK6OIyCExs2eccwuzXUdYHO4x8iM/X8nupnb+9MmlQ1iViITVunXrOO6447JdRtY8/vjjrF+/ng9/+MNZraOv12Gg42NkWKoKg3Qa7vs3+NZ8+Ot10NkM77sT3nMbzDxTIU1EREIjYkZac4mIiHDHHXfwwQ9+EAvhZ3l1fQRIdsL/XA0v/AZO/gCc9S89x5yJiIiEiJ+eX10fRUSWL1/O8uXLs13GIVFQ62iCX38ANj0EZ38R3vRPaj0TEZFQi5hmfRQRCbujO6g17YJfvdufsHrZ9+GU92e7IhERkcPmp+fPdhUiMpI450LZ/W+0OJR5QY7eMWote+Cn50Ltq7B8hUKaiIiMGqaujyKSIS8vjz179mg22CxxzrFnzx7y8vIO6nFHb4vaI//tZ3j88P/C1CXZrkZERGTIRMzQ5zER6TJ58mSqq6upqanJdilHrby8PCZPnnxQjzk6g1rdFlj5Y5j/PoU0EREZdSIGKfV9FJFAPB5nxowZ2S5DDtLR1/WxrR7uWA7RHDjrmmxXIyIiMuQiEU0mIiISdkdXi9rmx+D3H4Xm3fCB30LZlGxXJCIiMuTU9VFEJPyOnqCWaPchLZoDH74XpizKdkUiIiJHhLo+ioiE39ET1Fb+GBq3wYf+qJAmIiKjms6jJiISfkfHGLXqZ+CBr8Css2HGGdmuRkRE5IiK6DxqIiKhN/qDWqINViyH4iq46OZsVyMiInLERezQTq4qIiIjx+jv+vjCb6F5F3zwbiiqzHY1IiIiR1zEjJSCmohIqI3uFjXn4OkfQuXx6vIoIiJHjYgZafV9FBEJtdEd1LY/CztfgEVXgFm2qxERERkWmp5fRCT8RndQe/5OiObCiZdkuxIREZFhEzE066OISMiN3qCWSvjxaceeD/ll2a5GRERk2EQiGqMmIhJ2ozeobXoIWmvhpPdmuxIREZFh5c+jlu0qRETkcIzeoPb8ryF/DMw+J9uViIiIDCtNzy8iEn6jM6h1NMG6P8EJF0EsJ9vViIiIDKuIGSk1qYmIhNroDGrr74Vkm7o9iogcJrXKhFMkoq6PIiJhNzpPeL3xASiogMmLs12JiIRAZzJNNGJEIz1P47G7qZ3GtgRlBTmUF+Tw4PrdvFbbwomTSlk4bQwAT2zaQywSoSQ/RiwSIRqB/JwYVcW5bN7TytTyAupbO6lp7qAkL040YlQW55Jyjr+s3UV5QQ7Vda00tSc5eWoZqbSjKDfGC9saqCrJpbUzxfPVDWyvb6M4L8bxE0vZXNsCwM6GdiaPyeeYqmJ2N3VwxjFjeeTVWvY0d9DUnmRjTTPOQWVJLtV1bUQjxpQxBRTkRFm/q4mCnCiLppeTTDlqmztYuXkv7Yk0AGMK4xjGrsZ2nrr2bEynOAmVrj9l55xeOxGRkBp9Qc052PwoTH8TREZng6HISFDX0klrIkVlcS5N7Ule3tHIseOLKcqL8fKOJqpK8hhfmodzjpqmDqrr29hU08Kp08bQ1J5gUlk+nak0m2tbyYlFeH1vC7mxKI9tqOXY8cUsO3kS8aixvb6N+tYEL2xr4ImNe5hVWcTxE0po6Uiyaksdm2qaWTKzgrqWTjbWNLOppoX8IIAcP6GEpvYEKzfXMX1sAcmUoyAnyta6NnY2tLNkZjnPVzewems9qbSjODeGGRTnxSnNj/PSjsbu/Y1GenYlK8yJEo9FqG9N9Pn8+OnRYVxxLnUtnSQzHhuNGHmxCC2dqUE91znRCJPG5LOnuYM7nt5KXjyCYYwtzuF/1+7srus//9cvnx+PUpQXY2p5Ac451m5vZFpFIal0mtVb62lLpJhWXsCO+nZuuv9VIgZFuTEWTS+nrCAHh3/NnIMlM8rpSKbJi0cP9k9EsigShLO0g6hymohIKI2+oFa/BRq2wumfynYlIoclmUrzyq5mZlcWEY8aZsbupna21bWRE4swvaKQwtwY2+vb+MvanYwvySMejbB5Twtzqoppak9Q29TB1ro2ygtziEaMDbubqWvpZFxxLp3JNGOLc3l2Sx258Qhl+TlU17dRlBulODdOXjzCC9samFZRSH48yovbG3AOYhGjJD/O89X1pB2MKYiTTDmaOpL77cO8SaUkUmle3tm0332xiJF2br/uWbmxCB3JNF/8n7X7PWZSWT7/9/Lu7mBSnBdjekUhP3hoIxWFOcwaV8Q5x1fR0JbgkVdrueu5bZjB3PEl3PPCTnJiEdo6UxTlxqgqzePWxzdz0uQyPrp0JnnxCA1tCdJpR21zJ7sa27nmbXOZUJpHfWuCHQ3tHFNVxNI543hmy16e2LiH1s4UZx9XSVFunOaOJKm0I+UcjW0Jtta1MnlMAX9bX8PkMfksmVFOU0eSZMqxo6GN2uZOzjuhirRzjCnIYVxxLq/uaiYWNRraEhw3oYTapg4Kc2McU1VMTixCKu3YVtfGxLI8YlH/RdTWva3sbemkIMeH3LceX8XkMQWD+htzzpFMO2IRU6vLKNPVopZKu/1aikVEJBxGX1Db/Kj/Oe307NYho1prZ5KIGWbwQnUDrZ0pKktyGVeUy8rNdeTGIjS2J1i1uY7jJpQwsSyPP67ZQXFejPlTShlblMvelk5aOlKkgxaPrXtbmVpRQFtnis17Wqht7mDr3jZyYxGSwYetzmS6Rx1lBfF+W3S65MUj3d3ZKotzKS/MYU11AzlRY1dTB8dUFdPQlmBzbSszxxXS0pFkd2MHLR1JZlcV83x1A2nneOOsCuLRCJ3JNLsa27nqzFlMHlPAk5v2AHDh/Ils2dtKU3uCOZXFbK9v43fPVuMc/L93Hs/kMflMGVPAys17KS/M4aUdjcQjxsLpvsVmekUBzR1JjptQwtrtDTz9Wh3JVJqpFQWU5MWZU1XE5DEFNLQm2N3UTl48ysSyfKIRoyOZIjfWs8XHOUdje5J41CjIifW4HcCCyRYO5UPs+SdO4PwTJwxq2b87bdqg19s7YM0aV9TjejRiTK3oucyU8gKmlPvb5lQVD3pb4J+DuJpbRqVIpKtFTQPVRETCavQFtdefgPxyGDc325VIFrR2JsmPRzEzmtoTxCIRaps7eODl3WzY3cycqiL2NHeSdo6TJpdRnBdjd1MHBqzeWs+6HY1UFOUyvaKAyWPyeWl7IxtrWphSXsCG3U3MGlfEptoWnt1SR148SkFOlN1NHf3W09U6BFCcGyPlHD9/fPN+y5Xmx5leUcAfnttGLGKcMLGUKWMK+IczZvFabQs5sQjptKOiKIfZlUW0daZ5rbaZ7Q3tzBxbyJvnVrK5toVU2jF/Shmba1sYU5hDRWEO5YU5NLb51q7SgniP7abTrvsDXX/SaYeDfgPN+5ZM7fexHz1j5n63HT+xBIAL5k/s93GnTivn1Gnlfd5XWhDfbz96hzTwIaQ0P97n7V3U0iCjVVfXR+U0EZHwGn1BbccamHiyxqeNAptrW4jH/Ov45MY9NLYnOHXaGDbVtBCLGn9du4sJZXnUNnVS1+rHAD38Sg0FOVHy4lH2tnT2WF9+PEpbIoUZGPTZ5e7Y8cVU17Xx5+e3k3Z+bNDMcYU893ods6uK+fPzO5g2toArls6kpqmD+tZOLj11MhVFuexuamdnQzvHji8mkUqTTDnOPq6KrXtb2VjTzOIZ5eTHo2yoaaaxLUl5YQ5FQXibUJJHJGgxM4N49OD/fjNbX6pK8nrc1zvYdDlQSBvsMiIysnR3fVRSExEJrdEV1JKdsPtleMNbsl2JBJxz1LcmWLl5L7GoUVGYS21zB6X5cV7d3cxf1+5katB166H1NWzZ28LCaeW8VtvC6q31A667rCBOU3uSvFiEscW5NLQluOrMWXQm07QnU0wqyyeV9pNHnH1cFdPKC9jZ2M7YolzM4NENtSRTjqnlBSTTaeZU+nFAQHf3vpK8/VtvDtb0sYVMH1vYfX3u+JJ+l+3avojI4dg3mYiCmohIWI2uoFa7HtIJGH9StisZddoTKXJjke5uYzsa2njw5RpmVxZRmBvlvpd20ZFMkxuLUNfSyd7WBDsb2nhxWyNtif5ntptUls/jG/fQkUwzoTSP4yaU8NiGWiaU5vGvbz+OwtwYEYNjxhdTkhdj7XY/s2BbZ4rjJ5bQ1pkiHo1QkOO7vh1oQoSJZfndv7/52Mp+l8uJRbrH/YiIhE1318f0ARYUEZERa3QFtR3P+58KaoNW39rJa7UtzJtUSnsyzeMbagE/dueeF3by5CYfomqbO8iPR4lG/OQDbYlU9wQV4LvZRCNGIuUozY9THoyPeu+iKUwek88JE0uDyR0SVJbk0dCWYHJZPrMri+hIpulIpinOjR2wm93syp6TJfQ1NklE5GjX9VaqFjURkfAaXUFt5wsQL4CKWdmuZEToOn9VMu2oLM5l9dZ61lQ3sHVvKzsb2nl1dxMba/yJc8cV59LQmqAztS98FefFOOOYcZTkxagKwhX41jXn4AOnTaOmuYPGtgSLppdTVeLPmRU7yPFVefGoztEkIjKEur700hg1EZHwGl1BbdeLUHk8RI6+D/3OORrbknSm0jy6oYaapg7+unYXq7bUAT1P1lucG2N8aR4zxhZy8YLJTCjN4y9rdzKtopA3H1tJxKAjmea0mRWHMGZKE0+IiGSbxqiJiITfoIKamZ0PfAuIAj92zt3Q6/6pwK1AWbDMNc65e4a21EHYsxFmnjXsmx0OqbTjudfrOHlKGREzHt+4h6c372XV5r2s3d5IZzK931iwsUU5XPO2uRTlxnh9bysnTylj0fRyxhXn7rf+ixdMHq5dERGRI0zT84uIhN8Bg5qZRYHvAecA1cBKM7vbOfdSxmLXAXc6535gZscD9wDTj0C9/Uu0QdN2KN//vE1h5pzjtdoW/uOeddy/bjdL54yluq6N12pb/CQbVcW886QJ5MWjTCjNI2LG/CmlzKkqJi8W1SyCIiJHoe7p+Xufh0REREJjMC1qi4ENzrlNAGa2AlgGZAY1B3TNOV4KbB/KIgelbrP/WT5j2Dc9lJ57vY67ntvG6q31NLQl2NvSSVN7kmjEuOiUSfxh9TZmjSviO8tP4ZzjqzS2S0RE9qOujyIi4TeYoDYJ2JpxvRpY0muZ64G/mtkngULgrUNS3cHYu8n/DFmL2t6WTu5/aRfrdzXR1J7gzlXV5MejnDK1jBljCynOi3HchBLOmDOOKeUFfPa8Y6kszj2kEyKLiMjRoWsyEeU0EZHwGqrJRJYDP3fO/beZvQH4hZmd6FzPM7iY2ZXAlQBTp04dok0HuoPayG5R21zbwnNb60il4ZdPbuk+qXM86qe2/+jSGXzqrcdQlNv3SzMp4zxgIiIifdH0/CIi4TeYoLYNmJJxfXJwW6a/B84HcM49YWZ5wFhgd+ZCzrlbgFsAFi5cOLRHj72bIH+Mv4wwyVSadTua+NXTW7jj6X2NkxNK8/j8+cfyhpkVzJtUSmN7kvLCnCxWKiIio0FX10eNURMRCa/BBLWVwBwzm4EPaJcB7+u1zOvA2cDPzew4IA+oGcpCD2jvphHX7XFjTTMbdjfzrftf5aUdjZjBP5wxs3uGxWkVBT3GmCmkiYjIUOjq+qicJiISXgcMas65pJl9AvgLfur9nzrn1prZl4FVzrm7gX8GfmRmn8FPLHK5c8Pc32LvazB50bBusj/Vda3c+vhmfvLoa6QdjCmI8/VLT2LJjHKmVRRmuzwRERnluro+DvehWEREhs6gxqgF50S7p9dtX8z4/SXg9KEt7SA4B43boTR75wLb09zBrY9v5t4Xd/Lq7mYA3rNwMssXT2XmuCJK8+NZq01ERI4u+2Z9zHIhIiJyyIZqMpHsaquDdAKKqoZ9080dSV7a3sjnfruG1/e28oaZFVxy6mTeMW8CU8oLhr0eERERnUdNRCT8RkdQawmGwxVVDtsm02nHvS/u5Lo/vEBda4KSvBi/+9gbWTB15E1mIiIiRxedR01EJPxGR1Br3uV/DlOL2pqt9Xzut2t4ZVczJ04q4YZLTuKUqWVUFucNy/ZFREQG0hXUlNNERMJrlAS14CwARzioba9v4zsPvMpvn6lmXFEu33zvfN550kSdfFpEREaUSHBYSimpiYiE1igJal0takem66Nzjl89/Tpfu+dlOlNp3r1wCp8/71jKCjSdvoiIjDzq+igiEn6jJ6hFcyGvdMhX/fqeVq75/fM8vnEPb5xVwX9ecpImCRERkRFtX9dHBTURkbAaJUFtt+/2GByYhkI67fivv67nJ4++Rk40wn9cNI/li6dgQ7gNERGRI0HT84uIhN8oCWq7hrzb44qVW/nBQxt518kT+fz5c5lYlj+k6xcRETlSND2/iEj4jZKgthvKpg3Z6jbVNHPDves4bWY533zvyWpFExGRUIlENEZNRCTsRsd0hUPYorZy816WffcxohHjqxfNU0gTEZHQ0fT8IiLhF/4WtVQSWmqHJKjtamznY798lrHFufzi7xczeYwmDRERkfBR10cRkfALf1BrqwMcFIw9rNU0tif4yM9X0tqZ5FcfXaKQJiIioaWujyIi4Rf+ro+dTf5nbvFhreazd65h/c4mvv/+BRxTdXjrEhERySZ1fRQRCb/wB7WOZv8zt+iQV/Hkpj389aVdfOacYzjr2CNz0mwREZHh0tX1US1qIiLhFf6g1hkEtZxDC2rJVJqv/nkdE0rz+Ps3zRjCwkRERLKjq0VNY9RERMIr/EGt4/CC2vce3MgL2xr413ccR148OoSFiYiIZIdOeC0iEn7hD2rdY9QOPqj97ZUavv3Aqyw7eSLvPGniEBcmIiKSHZHg6O7U9VFEJLRGQVBr8T8PskVtR0MbH7/9WY6pKuarF807AoWJiIhkR3fXRwU1EZHQCn9QO8TJRG57YgutnUlu/sACinLDf5YCERGRLur6KCISfuEPat2TiQx+Sv32RIoVT7/OOcdXMa2i8AgVJiIikh1dsz6q66OISHiFP6h1NEEsD6KDbxX7zTPV1LUm+NAbpx+5ukRERLJkX4uagpqISFiFP6h1Nh/U+LTmjiTfuv8VFk8v5w0zK45gYSIiItmxb3r+LBciIiKHLPxBraP5oMan3fbEZmqbO7nm7XOx4EAmIiJysMxsipk9aGYvmdlaM/tUH8uYmX3bzDaY2fNmtmA4auua9VEtaiIi4RX+WTQ6mwc9Pi2ddtz+5Ou8cVYFC6aOOcKFiYjIKJcE/tk596yZFQPPmNl9zrmXMpZ5GzAnuCwBfhD8PKK6WtQ0Rk1EJLxGQYta06Bb1B5+tYZt9W28b8nUI1yUiIiMds65Hc65Z4Pfm4B1wKReiy0DbnPek0CZmU040rWp66OISPiFP6gdxBi1O55+nYrCHM49fvwRLkpERI4mZjYdOAV4qtddk4CtGder2T/MDbmuWR/V9VFEJLzCH9QGOUZtV2M796/bzaULJ5MTC/9ui4jIyGBmRcDvgE875xoPYz1XmtkqM1tVU1NzWDVFIur6KCISduFPLINsUfvNqq2k0o7LFqnbo4iIDA0zi+ND2u3Oud/3scg2YErG9cnBbftxzt3inFvonFs4bty4w6pLJ7wWEQm/8Ae1jmbIHXgyEeccd66q5g0zK5gxVie4FhGRw2d+6uCfAOucc9/oZ7G7gQ8Gsz+eBjQ453Yc6dq6uj6mlNREREIr3LM+OjeoFrU11Q28vreVT7xl9jAVJiIiR4HTgb8DXjCz1cFt1wJTAZxzNwP3AG8HNgCtwIeHo7Curo8aoyYiEl7hDmqJVsAdcIzaH9dsJyca4bwTNImIiIgMDefco8CAJ+R0fpDYx4enon32Tc8/3FsWEZGhEu6ujx3N/ucALWrOOf78/A7OPHYcpfnxYSpMREQkezTro4hI+IU7qHUGQW2AMWqv7GpmZ2M75xxfNUxFiYiIZFf3edQU1EREQivcQa2jyf8coEXt0Q21AJw+e+xwVCQiIpJ16vooIhJ+4Q5qiTb/M57X7yKPb6hlxthCJpXlD1NRIiIi2dXd9VGzPoqIhFa4g1o64X9Gc/q8O5FK8+SmPbxxVsUwFiUiIpJd6vooIhJ+4Q5qqSCoRfqeJOTFbQ20dKZ44yx1exQRkaPHvun5s1yIiIgcstER1KJ9B7WVm/cCsGjGmOGqSEREZESImJ/5WEREwincQS19oKBWx/SKAiqL+x/DJiIiMhpFzDQ9v4hIiIU7qA3Q9TGddqzavJdF08uHuSgREZHsi5iRSme7ChEROVThDmrppP/ZR4vaptpm6loTCmoiInJUikTU9VFEJMzCHdRSnf5nJLbfXWu2NgBwytSyYSxIRERkZFDXRxGRcAt5UOt/ev71u5rIiUWYMbZwmIsSERHJPnV9FBEJt3AHtQG6Pr68s4nZ44qIRcO9iyIiIociYqhFTUQkxMKdYronE9m/6+P6nY3MHV88zAWJiIiMDJGIaYyaiEiIDSqomdn5ZrbezDaY2TV93P9NM1sdXF4xs/ohr7Qv/UzPX9/aya7GDo5VUBMRkaOUH6OW7SpERORQ7d8U1YuZRYHvAecA1cBKM7vbOfdS1zLOuc9kLP9J4JQjUOv+uicT6RnU1u9sAlBQExGRo1bEIKUWNRGR0BpMi9piYINzbpNzrhNYASwbYPnlwB1DUdwBpfoeo/bKLh/U5o4vGZYyRERERpqIqeujiEiYDSaoTQK2ZlyvDm7bj5lNA2YADxx+aYOQTvjxaWY9bn51dzPFuTGqSnKHpQwREZGRJmJGWrM+ioiE1lBPJnIZ8FvnXKqvO83sSjNbZWarampqDn9rqcR+3R4BNtY0M6uyCOsV4ERERI4W6vooIhJugwlq24ApGdcnB7f15TIG6PbonLvFObfQObdw3Lhxg6+yP6lEn1Pzb9jdzKxxRYe/fhERkZAynfBaRCTUBhPUVgJzzGyGmeXgw9jdvRcys7nAGOCJoS1xAF1dHzM0tSfY1djB7EoFNREROXpFI4ZymohIeB0wqDnnksAngL8A64A7nXNrzezLZnZhxqKXASvccI5cTiUgmtPjpo01LQDMGlc4bGWIiIiMNDrhtYhIuB1wen4A59w9wD29bvtir+vXD11Zg5RO7tf1cePuZgBmqUVNRESOYhEzUjqRmohIaA31ZCLDK7V/18cNNc3Eo8bU8oIsFSUiIpJ9EXV9FBEJtZAHtc79WtSq69qYWJZPPBruXRMRETkc6vooIhJu4U4z6eR+Y9R2NbZTVZKXpYJERERGBnV9FBEJt3AHtT66Pu5WUBMREQmm5892FSIicqjCHdTSPc+j5pxjV2MHVcW5WSxKREQk+6IRf1wUEZFwCndQSyUgsi+oNXUkaUuk1KImIiJHvYhOeC0iEmrhD2rRfV0fdze2A1BZohY1ERE5upkZKeU0EZHQCndQS/c84fWuxg4AKovVoiYiIke3qKnro4hImIU7qPXq+rgraFGrUouaiIgc5dT1UUQk3MIf1DK6Pna3qGmMmoiIHOUiZqTT2a5CREQOVbiDWrpni9rupnaKcmMU5cYGeJCIiMjoZwYptaiJiIRWuINaquf0/LsbOzSRiIiICBCNmMaoiYiEWLiDWjrZM6g1tTOuSEFNREQkohNei4iEWriDWq/JROpbE4wpyBngASIiIkcHM0gpqYmIhFbIg1pnjxa1hrYEZQXxAR4gIiJydFDXRxGRcAt3UEsne7aotSUozVdQExERUddHEZFwC3dQy5hMpD2RojOZplQtaiIiIkQMnUdNRCTEwh3U0vuCWn1rAkAtaiIiIoCZaYyaiEiIhTeopVPg0t1dHxvafFAry9dkIiIiIvGogpqISJiFN6ilfDAj6k9u3RXU1KImIiIC8WiEzlQ622WIiMghCm9QSwdBLdLV9bETUFATEREByIlGSCQV1EREwiq8Qa27Rc13dezu+qjJRERERIjHInSm1PVRRCSswhvU0kn/s1fXxxK1qImIiJATjdCZTGW7DBEROUThDWop39UxczKRiEFxbiyLRYmIiIwMObEICbWoiYiEVoiDWlfXx31BrSQ/TiRiWSxKRERkZIhHTZOJiIiEWHiDWlfXx8i+86iVqdujiIgI4Gd9TKWdpugXEQmp8Aa1PlrUNOOjiIiIlxPzh/iEWtVEREIpxEEtGKMWBLX6tgSlBTrZtYiICPjJRAB1fxQRCanwBrVeXR8b1aImIiLSLR4ENZ1LTUQknMIb1Lq7PvpZHhvbEpTkacZHERERyOz6qDFqIiJhFN6glg6CWtCi1tKZpEhT84uIiAD7WtQ61aImIhJK4Q1q3WPUckilHe2JNPk50ezWJCIiMkLEo/50NRqjJiISTiEOasEYtWiMtkQKgAIFNREREQByNeujiEiohTeoZXR9bO30oa0gR10fRUREQF0fRUTCLrxBLeM8am2dalETERHJ1D3ro1rURERCKbxBrWt6/mgOLR0KaiIiIpm6Zn3UGDURkXAKb1DrmkwkEqMtoa6PIiIimdT1UUQk3MIb1IonwOxzIKeIVnV9FBER6SEnqvOoiYiEWXiboGaf7S9AS8dOAE3PLyIiEsjRrI8iIqEW3ha1DF1dHwvV9VFERATIOI+auj6KiITSqAhq6vooIiLSU/cYNbWoiYiE0ugIasGsj+r6KCIi4umE1yIi4TY6glp3i5q6PoqIiIBmfRQRCbvREdQSSXJjEaIRy3YpIiIiI0JcLWoiIqE2qKBmZueb2Xoz22Bm1/SzzHvM7CUzW2tmvxraMgfW2pHS+DQREZEMmp5fRCTcDthX0MyiwPeAc4BqYKWZ3e2ceyljmTnAF4DTnXN1ZlZ5pAruS2tnSt0eRUREMnTN+tihro8iIqE0mBa1xcAG59wm51wnsAJY1muZjwLfc87VATjndg9tmQNrSyTVoiYiIsPOzH5qZrvN7MV+7j/LzBrMbHVw+eIw1kZONKKujyIiITWYZqhJwNaM69XAkl7LHANgZo8BUeB659z/DkmFg+Bb1BTURERk2P0c+C5w2wDLPOKce+fwlBP4+Tth7Bzi0fNIqEVNRCSUhqq/YAyYA5wFTAYeNrN5zrn6zIXM7ErgSoCpU6cO0ab9GDVNzS8iIsPNOfewmU3Pdh37aamF/DLisYjOoyYiElKD6fq4DZiScX1ycFumauBu51zCOfca8Ao+uPXgnLvFObfQObdw3Lhxh1rzfloTSQo1Rk1EREamN5jZGjO718xOGJYtRmOQSqrro4hIiA0mqK0E5pjZDDPLAS4D7u61zB/wrWmY2Vh8V8hNQ1fmwFo71aImIiIj0rPANOfcfOA7+ONln8zsSjNbZWarampqDm+rkRikk8SjETqTmvVRRCSMDhjUnHNJ4BPAX4B1wJ3OubVm9mUzuzBY7C/AHjN7CXgQ+Jxzbs+RKro3Tc8vIiIjkXOu0TnXHPx+DxAPvtDsa9mh63USiUM6QY66PoqIhNag+gsGB5d7et32xYzfHfBPwWXYtXYmNT2/iIiMOGY2HtjlnHNmthj/BemR/yIzEoN0ynd91GQiIiKhNCrSTVtCLWoiIjL8zOwOfNf/sWZWDfwbEAdwzt0MXAp8zMySQBtwWfDl5pEVjUGyk3jM1KImIhJSoQ9qnck0iZRTUBMRkWHnnFt+gPu/i5++f3hF4pBuJa7JREREQmswk4mMaG2JFAD56vooIiLiRWJ+jFo0Qqe6PoqIhFLog1rXASg3FvpdERERGRrRuB+jpslERERCK/TppqtLR0409LsiIiIyNCJRSCXU9VFEJMRCn266DkDxmGW5EhERkREiEod0cMJrnUdNRCSURk9QU4uaiIiIF4xRi6vro4hIaIU+3XQG3xQqqImIiASi/jxq8ahpMhERkZAKfbrRGDUREZFeIjFIJciNaYyaiEhYhT7dqOujiIhIL8EYtXhUXR9FRMIq9OmmszuoaTIRERERIBij5oNaQl0fRURCKfRBLZEKxqjpPGoiIiJe1Ae1nFiEDgU1EZFQCn266fqmUGPUREREAsEYtYJ4lGTaaUIREZEQCn260Rg1ERGRXoIxagW5MQDaOlNZLkhERA5W6NONxqiJiIj0EokBjqK4v9rSmcxqOSIicvBCH9S6x6ipRU1ERMSL+pa0wrj/ErNVQU1EJHRCn266z6OmyURERES8iA9qRTF/jGzpUNdHEZGwCX260Rg1ERGRXiK+z2NB0KKmro8iIuET+nTTNZOVxqiJiIgEgha1wqBFrVUtaiIioRP+oKYWNRERkZ6CMWoF/getCQU1EZGwCX26SSQ1mYiIiEgPka6g1tWipq6PIiJhE/p0k0iliUaMaERdH0VERIDuMWr5QYtai86jJiISOqMiqGl8moiISIagRS0/ohY1EZGwCn1Q60yl1e1RREQkUzBGLW5pcmIRtaiJiIRQ6BNOIpUmR0FNRERkn6BFjVSCwpyoTngtIhJCoU84iaRTi5qIiEimYIwa6SQFOTGd8FpEJIRCn3ASqTTxmMaoiYiIdOtqUUsnKcxVi5qISBiFPqhpjJqIiEgv0X1BrSAnpjFqIiIhFPqEozFqIiIivWSOUcuNatZHEZEQCn3CSaQ0Rk1ERKSH7jFqCbWoiYiEVOgTjs6jJiIi0kv3GLWUZn0UEQmp0Ae1zqTGqImIiPQQ3df1sSBXsz6KiIRR6BNOIuVP5ikiIiKBzFkf1aImIhJKoU84GqMmIiLSS6/zqLV2pkinXXZrEhGRgxL6hKMxaiIiIr1Eov5ncB41gLaEuj+KiIRJ6IOazqMmIiLSSzRoUUslyM/x3SBb1P1RRCRUQp9wdB41ERGRXjLGqBUFLWrN7QpqIiJhEvqEk0hqjJqIiEgPGWPUygpyAKhrTWSxIBEROVihTziJVJp4TGPUREREumWMURsTBLX61s4sFiQiIgcr9EFNY9RERER6yRijVq4WNRGRUAp9wtEYNRERkV4yxqiVFfrQVteiFjURkTAJfcLRedRERER6yRijVpwbIxYx6tT1UUQkVEKdcFJpRyqtoCYiItJDxhg1M6OsIEddH0VEQibUCSeRSgNoMhEREZFMZr77Y8qHszEFcXV9FBEJmVER1DRGTUREpJdIHNL+3GljCnLU9VFEJGQGlXDM7HwzW29mG8zsmj7uv9zMasxsdXC5YuhL3V8i5QDU9VFERKS3SKw7qJUVxKlX10cRkVCJHWgBM4sC3wPOAaqBlWZ2t3PupV6L/to594kjUGO/urs+KqiJiIj0FN0X1MoLc3hua3126xERkYMymISzGNjgnNvknOsEVgDLjmxZg9OZ7ApqGqMmIiLSQ8YYtbKCHOpbO3HOZbkoEREZrMEEtUnA1ozr1cFtvV1iZs+b2W/NbMqQVHcA3WPUYmpRExER6aHHGLU4iZSjuSOZ5aJERGSwhirh/BGY7pw7CbgPuLWvhczsSjNbZWarampqDnujGqMmIiLSj4wxamMKcwA0Tk1EJEQGk3C2AZktZJOD27o55/Y45zqCqz8GTu1rRc65W5xzC51zC8eNG3co9fagMWoiIiL9yBijNqbABzXN/CgiEh6DSTgrgTlmNsPMcoDLgLszFzCzCRlXLwTWDV2J/esMglpMY9RERER6yhijVl4YB2CPzqUmIhIaB5z10TmXNLNPAH8BosBPnXNrzezLwCrn3N3AP5rZhUAS2AtcfgRr7pZKB10fI2pRExER6SFjjFpVSR4Auxras1mRiIgchAMGNQDn3D3APb1u+2LG718AvjC0pR1YV1CLqEFNRESkp0i0R1Azg+31bVkuSkREBivUTVHpYJrhiJKaiIhIT9F9LWrxaISq4jy21atFTUQkLMId1PwQNSKmoCYiItJDxhg1gIlleexoUIuaiEhYhDuoBS1qmvRRRESkl0gc0qnuqxPK8tX1UUQkREIdcVJBUDO1qImIiPQUiUJ6X4vapLJ8tje044Jjp4iIjGyhDmpdB5uogpqIiEhPGWPUACaW5tGZTGuKfhGRkAh1UEtpjJqIiEjf9hujlg9o5kcRkbAIdVDbN+tjlgsREREZaaJxBTURkRALdcRJd59HTS1qIiIiPcTyIbkvlHUFteo6BTURkTAId1ALxkMrqImIiPQSz4fEvlA2piBOaX6cTbUtWSxKREQGK+RBTdPzi4iI9CmeD4l9J7g2M+ZUFrFhV3MWixIRkcEKdcRJa3p+ERGRvsXzIdHa46bZlUVsqFFQExEJg1ER1DQ9v4iISC/xAn8etdS+KfpnVxaxt6WTvZqiX0RkxAt1UNP0/CIiIv2I+8lDMicUmVVZBMCG3WpVExEZ6UId1DQ9v4iISD9ief5nxoQis8cpqImIhEWoI46m5xcREelHvMD/zBinNqksn/x4lFd2NWWpKBERGaxwB7Vgev5oREFNRESkh66ujxkzP0YixnETilm7vSFLRYmIyGCFOqilumd9zHIhIiJyVDKzn5rZbjN7sZ/7zcy+bWYbzOx5M1swbMV1B7WeMz/On1LGC9saSHQN9BYRkREp1EHNadZHERHJrp8D5w9w/9uAOcHlSuAHw1CT1x3U2nrcfPKUMtoTaXV/FBEZ4UId1FIaoyYiIlnknHsY2DvAIsuA25z3JFBmZhOGpbjuMWr7BzWA1Vvrh6UMERE5NKEOal1j1CIaoyYiIiPTJGBrxvXq4LYjr2vWx2TPoDa1vIAxBXHWKKiJiIxo4Q5q3S1qWS5ERETkMJnZlWa2ysxW1dTUHP4K+2lRMzNOmTqGlZvrDn8bIiJyxIQ7qHWNUVNSExGRkWkbMCXj+uTgtv04525xzi10zi0cN27c4W+5n8lEAN44q4LXalvYVt+2330iIjIyhDqodc36qDFqIiIyQt0NfDCY/fE0oME5t2NYttzH9Pxdls7xQfCxV2uHpRQRETl4oQ5qQU7T9PwiIpIVZnYH8ARwrJlVm9nfm9lVZnZVsMg9wCZgA/Aj4OphK26AFrVjqooYW5TLIxsU1ERERqpYtgs4HF1j1DQ9v4iIZINzbvkB7nfAx4epnJ66JhNJ7N+90cx40+wKHn61llTaaQiBiMgIFOoWNXV9FBER6YeZn1CkjxY1gLccV8Xelk5Wb9WkIiIiI1Gog5qm5xcRERlALA+S+49RAzjzmHHEIsZfX9o1zEWJiMhghDuopZ2m5hcREelPvKDPro8ApflxTptZwf0KaiIiI1K4g5pTv3oREZF+xfP77foIcO4JVWysaWHdjsZhLEpERAYj1EEt5Rym8WkiIiJ9i+f1OT1/lwtOmkhONMKdq7YOY1EiIjIYoQ5qzmnGRxERkX4NMJkIwJjCHM45oYq7nttGRzI1jIWJiMiBhDqopTRGTUREpH/x/H7HqHV5z8Ip1LcmuP+l3cNUlIiIDEaog1raOc34KCIi0p9YPiQHDmpvmj2WiaV5/FrdH0VERpRwB7W00znURERE+jOIFrVoxLj01Mk88moN2+oHXlZERIZPuIOaQ7M+ioiI9GeA6fkzvXvhFAy49fHNR7wkEREZnFAHtZTTGDUREZF+HWB6/i5Tygu4cP5EfvHEFmqbO4ahMBEROZBQBzXn1PVRRESkX/G8QbWoAXziLXPoSKb47gMbjnBRIiIyGKEOaimNURMREelfbgkk2yHZecBFZ1cWcdniqdz2xGbWbm8YhuJERGQgoQ5qaYe6PoqIiPQnf4z/2V4/qMX/5by5jCnI4bo/vEg67Y5cXSIickAhD2qanl9ERKRfeWX+Z1v9oBYvLYhz7duP47nX6zVdv4hIloU7qKnro4iISP/yy/zPQbaoAVy8YBJLZpRzw70vs0cTi4iIZE24g5qm5xcREelfV9fHtrpBP8TM+Mq7TqSlI8nX7n35CBUmIiIHEuqglnIONaiJiIj04yC7PnaZU1XMlWfM5LfPVPPHNduHvCwRETmwUAc15xxRJTUREZG+HULXxy6ffusxLJw2hs//9nk21jQPaVkiInJggwpqZna+ma03sw1mds0Ay11iZs7MFg5dif3T9PwiIiID6G5RG3zXxy45sQjfe/8C4lHjmt89r1kgRUSG2QGDmplFge8BbwOOB5ab2fF9LFcMfAp4aqiL7E/aoVkfRURE+hONQU7xQXd97FJVksf/e+fxrNxcx7V3vUAylR7a+kREpF+DaVFbDGxwzm1yznUCK4BlfSz378B/Au1DWN+A/KyPw7U1ERGREMovO6Suj10uPXUyn3jzbFas3Mq1d72Ac2pZExEZDoMJapOAzJOpVAe3dTOzBcAU59yfh7C2A0o7p1kfRUREBpJfdkhdH7uYGZ8971g++ZbZ3Lmqmu89uEFhTURkGMQOdwVmFgG+AVw+iGWvBK4EmDp16uFumpTzBxARERHpR17ZIXd9zPSZtx7D63tbufGvr1DXmuC6dxynY7CIyBE0mKC2DZiScX1ycFuXYuBE4KHgDXs8cLeZXeicW5W5IufcLcAtAAsXLjzsr+P8rI+HuxYREZFRLL8Mal897NVEIsY333MyYwpy+MmjrxGLGv9y3lyNFRcROUIGE9RWAnPMbAY+oF0GvK/rTudcAzC267qZPQR8tndIOxI066OIiMgB5I85rK6PmSIR498uOJ5EKs0P/7aJl7Y38t/vmU9lcd6QrF9ERPY54Bg151wS+ATwF2AdcKdzbq2ZfdnMLjzSBQ4k7Zy+yRMRERnIEHV97GJmfOVdJ/LVi05k5ea9vO2mR7j18c10JjUjpIjIUBrUGDXn3D3APb1u+2I/y551+GUNTjoNkVCfsltEROQIyx8DqQ5ItEE8f0hWaWa8f8k0Fk8v59q7XuDf7l7L/6zexnfft4CJZUOzDRGRo12oY07aqeujiIjIgPLL/M8h6v6YaU5VMXf+wxv43vsW8PLOJt5840N85U8vsae5Y8i3JSJytAl9UNP0/CIiIgMoHOd/Nu8+Iqs3M95x0gT+8ukzuGD+RH762Guc+V8P8b0HN9CeSB2RbYqIHA1CHdQ0Pb+IiMgBFE/0P5t2HNHNTCkv4MZ3z+evnzmDN8yq4L/+sp4zvv4gn/vNGrbubT2i2xYRGY1CHdQ0Pb+IiMgBlEzwPxu3DbzcEJldWcyPPriQFVeexvwpZdzzwg4uvflx/mf1NqrrWnWybBGRQTrsE15nk6bnFxEROYCiKrAoNB7ZFrXeTptZwWkzK1i/s4kP/fRpPrViNQCVxbmcdew4rnvn8ZTkxYe1JhGRMAl1UEs7ND2/iIjIQCJRH9aOcNfH/hw7vphH/uXNvLyjiee21vHMljp+/+w2Ht+4h9NnjeWKpTOYU1WcldpEREaycAe1tEM5TURE5ABKJgxb18e+xKMR5k0uZd7kUj74huksXzyVm+5/hXte2MFdz23juIklvPnYcVx5xkwKckL90UREZMiE+t1Qsz6KiIgMQslEqHkl21V0O21mBSuufAO1zR1894ENvLSjkZvuf5Uf/m0Ti2aUM29SCW+fN4GCnBjTygvUe0ZEjkqhDmop5zTro4iIyIEUT4RNf8t2FfsZW5TL9ReeAMCzr9dx17PbWLWljh/+bRPfe3AjAHMqiyjMjTG1vIB/fcdxVJXkZbNkEZFhE+qg5hxEFdREREQGVjIBOhqhowlyR+Z4sAVTx7Bg6hgAapo6ePiVGlo7k/zmmWoiBn9Zu5P/fXEni2eUU1GUw5uPrWR8aR5zKouoKMrNcvUiIkMv1EEtpTFqIiIiB1Yyyf9s3AHjRmZQyzSuOJdLTp0MwN+9YToAW/a0cOvjW3h68x7W72rif1Zv717+jbMqGF+ax5Y9rVyyYDKXnDqJ3Fg0G6WLiAyZUAe1tHPqty4iInIgxRnnUht3THZrOUTTKgr54gXHA34ysRe3N9DQluC51+u57YktrN5az+Qx+Vx71wvcdP8rlObHqSrJY3ZlEZPK8plYls/SY8bqlAAiEhrhDmo6j5qIiMiBVcz2P2tfgVlvzm4tQyASMU6aXAbA0jnjuOrMWaSdIzcW4eFXa/nVU1sA2NHQzm9WbaWlMwVALGKcMrWMvHiUeZNK6UymKc6Lc+4JVcwdX6xx7yIyooQ7qGmMmoiIyIEVj4eCCtj1YrYrOSJyYpHu3888ZhxnHjOu+7pzjuaOJOt3NnHful2sfG0vda2d3Py3jcSiERKpNN8MWuByYhGmjMln3qRSFkwbw+zKIpyD2uYOImbMGFvIpLJ89eYRkWER8qDmiEQOvJyIiMhRzQyqToBda7NdybAzM4rz4iycXs7C6eXdtzd3JMmNRahvTXD/ul28uK2BRCrN5j2t/OaZam59Ykuf68uLRxhfkscbZlXwlrlVFOZE6Uyl2d3YwelzxrKtro0JpXlMKS8Yrl0UkVEq9EFN3RREREQGoepEeObnkE5BRBNtFOX6j0DjinNZvnhqj/uSqTSv7Gpmy54WACpLckmmHJtqW9i4u5nqujZ+/+w27nh6a7/rnzwmn9xYBOfgnOOr6EylKcqNccLEUkryYzgHpflxxhTmUJYfpyAnqs80ItJDyIOauj6KiIgMStUJkGiFus1QMSvb1YxosWiE4yeWcPzEkh63L5lZ0f17Q2uCLXtbaO1METGjKDfG316pYcbYQqrrWnm+uoGOZIqGtgQ/fHgThTlR2hIp0q7vbeZEI5QWxFkyo5zK4jxqmjuIR43OZJozjhlHfjxKY3uCsUW5nDK1jMpinU9OZLQLdVDT9PwiIiKDVOVPLM3OFxTUhkBpQZyTCsp63NY72HVJptLEohE6k2le2NZAZzKNGdS3Jmho66S+NUFda4Kapg7uX7eL9kSKCaV5dCbTpJzjT8/v2G+dXV0uS/LiLJ5RjhmMK8olPydGeyLF5DH51DR3cGxVMXWtCY6fUMJpM8vVaicSIqEOapqeX0REZJDGHQeRGOx8Hk54V7arOarEon5AfU4swqnTxgy4bCKVBiAePCaddqzf1UQ0YhTnxdhe385zr9exrb6NvHiU3Y0dPLlpDzmxCA821JBMp4lHI7R2pohGjFRGE15xXoxYxGjpTFGSF6O5I8nc8SVMGpNPSV6ckrwYFUU55MairNpSR1VxLoW5McwgPx6lND9OWUGckvw4YwpymDG2kGjEiEWMRMpP2lJemHOEnkWRo0+4g5qm5xcRERmceB5UHgfbns12JTKAroDWJRIxjpuwr6VuQml+v2EvmUrjgIgZDW0JSvJibKxpoawgzt9eqWHttgYSaUdxbozG9gR58ShrtzeybkcjjW1JmtoTdCR9UKwqyaW+dd/1vnQFwYmleaQd7GpqZ9E037rX2pliakUB0ysKqG9NsKOhncLcGNPKC2juSHLGMWN5dZcf7zehLI/Z44pIph2JVJqJZfm0J1Jsq2ujJD/OKVPLaOlIkZ8TpbI4d7/nSGS0CndQc/5NQkRERAZh4gJ46X/AOT8TpIwqsYwA09Wydez4YgDes3AKLJxywHXUt3bS0JZganlBdzfJdNrRlkhR35agoTVBQ1uC2uYOXt7ZSDQS4cVtDaTSjnedMoknNtaSG48ypjCH1a/X878v7qQgJ8qUMQU0tif445rt5MYi/PzxzQCUFcSpb00Meh+jEWNCaR7OwdjiXGaPK2JvSwcFuTGcc8wYW0hjW5K2RIqSvDhFeb4r6EvbG5k7vpjxpXlEzIgYFOTGKMuPU9/mu4bm50RpT6SIRSIU58UozosRjRiv721lekUheXE/CU97IkVtcwdVJXkKjXJEhTqopZzTcUZERGSwJi2AZ2+FvZs0Tk36VFaQQ1lBz+6LkYhRmBujMDfGpLL87tsvmD/xgOtLp/1nta7Ql0z5cXd/XbuLqeUFzJ9SRn1rJ6/vbSU3FiUaga11bRTEo0wsy6e6ro0NNc2U5MVo7fStbFvrWomYsam2hUderWFccS5te1oB+N8Xd1KY40NWQ1uCls4UsYgxu7KI257YS2eq/xbCgeTFI0TMd/NsT6S715Mfj1KYG2XymAJqmjpoaEswoTSPeZNK2dnYTjLlSDvX3d108pgCzKCupZOnN+/luAklHFNVxNgi31LY1J6ksT1BeyLF1PICUmlHRWEOefEoDj8O8enNe/eNQ2zqoLI4jwXTxlDT1E5je5KJpfnk50SYWJZPbizK63tbaW5Pcuz4YsYW5bCjoZ3mjiSdyTSTx+Tv93oDtHQkqWvtpKwgp3uGVBl+oX7mnXOa9VFERGSwJi7wP7c/p6Amw6L3XAKxaIQYPUNe73A4u7K4+/cp5QW8YVYFg9WeSJETjXRv1znX3QOrM5mmI5kinfZf9je1J6hvTVCcF2Pt9kbSzpEbi5JK+/ua2pN0ptJMKM3jxW2NACTTafLjUaZVFLK7qZ2WjiTNHUleq21h/pRSxpfk8+ruJh7ZUNt9ioYoESaVxdnT0smTm/YAkBuLcO7x41m/q5E/Pb+ju1UxJ+pb83JiEX7/7DbMfAN4ppxYhLxYhMb2JDnRyEGFz/y4n300c10nTCyhoTVBMu1IpR3JdJrdTR045+9fPL2cVNoFYTpCcb4fz1iSHycW8d1sOxJpTphYQiRiNLT6Fteu13ZbfStFuTFK83MoK4jTmUxT29xBMu2YObaQKeUFtCdSwXNj1LV2kkw7zp5bSWtnipljCynKixExY8ueFmLRCMdUFbFmaz3HVBVz8tQyKgpzue+lXbxW28LU8gIWzRjDuh1NGBCLGi8Gk/hMLMsnHo0Qjxq5sSgVRTnUtyaoKsljxthC6lo7AciLR3l9TyvNHUnKCuLd4zid863L/kuFI59BQh3UUhqjJiIiMniVx0EsD7Y9A/MuzXY1IkOuq3tiFzMjGnxUzIlFyIn17B46LciAM8cVDbjeixcMaZn76Uymg6AY6W597Aqdu5s6SKR8K97OhnZOnTaGvHiUvS2dFOXGeH1vC1v2tFJVkkdxXowdDe20J1Js3dtKKu0YX5pPcV6Ml3c2sXVvK7PGFTKmMIdYJMKjG2rYsLuZ4yaWEIsYUTOiEWNKeQHjS/NYu62B57bWE40Yi2eUk0ilaWxP0tiWYFt9G8mUozQ/TiRi3PrEZiJmlObHKS/MIe0cz29rYGp5Advq23lpeyN1rQly4xHGFuViwN/W13QHzanlBeTFIxTmxuhIpPjGfa/sNyFOf/oKtEMtP/jb6gq6BTlRrjxjJp9+6zFHbJuhDmppt/83NSIiItKPaBymvgFevQ/O/1q2qxGRQGaA7NIVOseX7jtn3qyMQNk1DnF2ZXGPVshpFYV9buP02WP3u+38E8cPXNggxjV2SacPfjb2VNpR09RBLGpUFOZ0h1QXdBfNj0eprmulLZEimXKML81jT3Mnr9W2sGRGOZtqm3m+uoHa5g5OnFjKGceMY/XWetZU13Py5DJyYhE6kmlmjiukOC9ObVMHyXSazqSjPZmitqmD4rw4m2qbqWnqYGxRLg7f9XNaeQGl+XHqWhNU17VS29xBKg1ji3PoSKRp7khy4sTSg9rfgxXaoJYO0rVymoiIyEE49u1w7+eg9lUYOyfb1YjIKHEojSfRiPUIol0sOIk87B88xxbldk+Sc2phOadOK+9x/+mzx/YZSoF+x9sdTPfa4RTaqWrSQfumxqiJiIgchGPP9z/X35vdOkREZEChDWqpIKip66OIiMhBKJsKVfNg3d3ZrkRERAYQ2qDWNWBQk4mIiIgcpHmXQvVKqN2Q7UpERKQfoQ1qXV0f1aAmIiJykE56L1gE1vwq25WIiEg/QhvUUt2TiSipiYiIHJSSCTDrbFizAtKpAy8vIiLDLrRBreuUChqjJiIicghOfh80boPX/pbtSkREpA/hDWqanl9EROTQHft2yCuF1er+KCIyEoU3qHVNz6+kJiIicvDieXDipbDuj9Bck+1qRESkl9AGta7p+U1j1ERERA7NaR+DdBIe+PdsVyIiIr2ENqh1Tc+vE16LiIgcorFzYPGV8OxtsOP5bFcjIiIZQhvUUhqjJiIicvjO/Dzkj4G/XLvvW1AREcm60Aa17vOoKamJiIgcuvwx8JZ/hc2PwOPfVlgTERkhwhvU0v6nzqMmIiJymBZcDsddAPd9ER78j2xXIyIihDmodc/6mOVCREREwi4ag3ffBid/AB7+Orz4u2xXJCJy1AttzOma9VEtaiIiIkMgEoF3fhMmL4I/fxba6rJdkYjIUS20Qc0pqImISJaZ2flmtt7MNpjZNX3cf7mZ1ZjZ6uByRTbqHLRYDrzjG9BeDw/dkO1qRESOaqENaimNURMRkSwysyjwPeBtwPHAcjM7vo9Ff+2cOzm4/HhYizwUE06ChR+Bp34IGx/IdjUiIket0Aa17lkfldNERCQ7FgMbnHObnHOdwApgWZZrGhrnfBnGHQu//YjCmohIlsSyXcCh0vT8ItJbIpGgurqa9vb2bJdy1MrLy2Py5MnE4/FslzIcJgFbM65XA0v6WO4SMzsDeAX4jHNuax/LjCw5hXDZr2DF++AXF8MlP4Z5l2a7KhGRo8qggpqZnQ98C4gCP3bO3dDr/quAjwMpoBm40jn30hDX2oOm5xeR3qqrqykuLmb69OmY3huGnXOOPXv2UF1dzYwZM7JdzkjxR+AO51yHmf0DcCvwlr4WNLMrgSsBpk6dOnwV9qdiFnz0QfjlJXDXVdDe4LtE6n9LRGRYHLDr4yD74P/KOTfPOXcy8HXgG0NdaG+anl9Eemtvb6eiokIhLUvMjIqKiqOpRXMbMCXj+uTgtm7OuT3OuY7g6o+BU/tbmXPuFufcQufcwnHjxg15sYckpwCW3wHTT4c//xP88mLY+1q2qxIROSoMJuYcsA++c64x42oh4IauxL51Tc+vD2QikknvCdl1lD3/K4E5ZjbDzHKAy4C7MxcwswkZVy8E1g1jfUMjvww+cBe8/UZ4/Un49inwuyugsyXblYmIjGqDCWp99cGf1HshM/u4mW3Et6j949CU17+u6fmjR9eHAhEZwfbs2cPJJ5/MySefzPjx45k0aVL39c7OzgEfe/PNN3PbbbcNU6WDU19fz/e///1slzFiOeeSwCeAv+AD2J3OubVm9mUzuzBY7B/NbK2ZrcEfGy/PTrWHKRKBxR+FT6yC0z8FL/wWfvxW/zOdynZ1IiKj0pBNJuKc+x7wPTN7H3Ad8KHeywxl/3tNzy8iI01FRQWrV68G4Prrr6eoqIjPfvaz3fcnk0lisb7fdq+66qrhKPGgdAW1q6++OtuljFjOuXuAe3rd9sWM378AfGG46zpiSifBOV+CaW+E//0C/O7v4ZFvwFv/DWaf4wOdiIgMicG8ox6wD34vK4B39XXHUPa/3zfr42GtRkTkiLr88su56qqrWLJkCZ///OfZuHEj559/PqeeeipLly7l5ZdfBnywu/HGGwE466yz+Jd/+RcWL17MMcccwyOPPALA5s2bWbp0KQsWLGDBggU8/vjjADz00EOceeaZLFu2jJkzZ3LNNddw++23s3jxYubNm8fGjRsBqKmp4ZJLLmHRokUsWrSIxx57rHvbH/nIRzjrrLOYOXMm3/72twG45ppr2LhxIyeffDKf+9zncM7xuc99jhNPPJF58+bx61//elifSxlBjjnPt65d+lNItMKv3gP/MRF+eSk8fyd0NGe7QhGR0BtMi1p3H3x8QLsMeF/mAmY2xzn3anD1HcCrHGHpdNd51NSiJiL7+9If1/LS9sYDL3gQjp9Ywr9dcMJBP666uprHH3+caDTK2Wefzc0338ycOXN46qmnuPrqq3nggf3PU5VMJnn66ae55557+NKXvsT9999PZWUl9913H3l5ebz66qssX76cVatWAbBmzRrWrVtHeXk5M2fO5IorruDpp5/mW9/6Ft/5zne46aab+NSnPsVnPvMZ3vSmN/H6669z3nnnsW6dHzL18ssv8+CDD9LU1MSxxx7Lxz72MW644QZefPHF7lbC3/3ud6xevZo1a9ZQW1vLokWLOOOMM5gwYcJ+9ctRIBKBEy+B4y6EtX+Abavg5T/D7z8KuSVwwkVQNgUWfAiKKrNdrYhI6BwwqDnnkmbW1Qc/Cvy0qw8+sMo5dzfwCTN7K5AA6uij2+NQC3IaUZ1HTURGuHe/+91Eo1Gam5t5/PHHefe73919X0dHR5+PufjiiwE49dRT2bx5M+DPE/eJT3yC1atXE41GeeWVV7qXX7RoUXdgmjVrFueeey4A8+bN48EHHwTg/vvv56WX9p05pbGxkeZm3/Lxjne8g9zcXHJzc6msrGTXrl371fToo4+yfPlyotEoVVVVnHnmmaxcuZILL7xwv2XlKBKNw0nv9pfzvgavPwGrfgJr74KORnjs23DSe2D8PEi0QzQGs94C5TOzXbmIyIg2qDFqg+iD/6khruuAumZ9VE4Tkb4cSsvXkVJYWAhAOp2mrKysu4VqILm5uQBEo1GSySQA3/zmN6mqqmLNmjWk02ny8vL2Wx4gEol0X49EIt2PT6fTPPnkkz0e19fjM7cpclAiET+V//TT/fXaV+Ghr8Fzt0OyLWO5OLz96zD1DTD2GGjdC3klEMvte70iIkeh0I7w6h6jpq6PIhISJSUlzJgxg9/85jeAn712zZo1g358Q0MDEyZMIBKJ8Itf/IJU6uBm2zv33HP5zne+0339QIGxuLiYpqam7utLly7l17/+NalUipqaGh5++GEWL158UDXIUWbsHD+O7Zot8Jm18LmN8MlnYepp8KfPwPdPg69NgRtnw/cWw23L4JsnwgNfhcYd+9bjnL+IiBxFhmzWx+GmMWoiEka33347H/vYx/jKV75CIpHgsssuY/78+YN67NVXX80ll1zCbbfdxvnnn9/dUjdY3/72t/n4xz/OSSedRDKZ5IwzzuDmm2/ud/mKigpOP/10TjzxRN72trfx9a9/nSeeeIL58+djZnz9619n/PjxB1WDHKViuVA62f9eOBY+8HvY/DC07IGtT0LReFj9S9j5AkyYDw//Fzz6DT/+bcJ8eOZnkF8Op10NLTWw4O8gt3jf+pOdkE76E3SLiIwS5rL0DdXChQtd1yD4Q3HfS7v46G2r+NMn38SJk0qHsDIRCat169Zx3HHHZbuMo15fr4OZPeOcW5ilkkLncI+RoZTsAJeGeD7s3QQrfwLP/RLa6333yMYd0Bm08OaV+osDTrwIXr0PWvfABd/2E5iMmwuRaDb3RkRkUAY6Poa2RS0VtKipQU1ERGQUyByfVj4TzvsqnPsVaKmFgnJo3OYDXCwfnr3Vh7rWPfDYtyBeCAUVcMd7/eNziiGW41vjyqb5Vry8MuhsgZPf51v3uj5ANO+Gpp1QdYLCnYiMKKENak5j1EREREY3MygKzrtaNtVfAKYu2bfMhvt918nSyfD6k74FrnoVpDr89R3PQ1sduGBM50P/4X9Gc2HMdKjb7JfNK4Ppb4KqE/12o3Hfkjd5EeSPgfYGf8640il+fTlFEN9/Yh4RkaES2qCm6flFRESE2W/d9/ux5/uf8y/ruUyiDTpbfdBa+3vfspZog5r1MO2NMGUJbHkUtjwOL/9p4O3F8iDZ7lvx8sdAosWHxNKpvttl6WTfjTO32LcCNu3055Krftq3CB63DOa8dd+4umgc6rb4WS8LxsJrf/PnoZt86tA+TyISOqENapqeX0RERAYlnu8vVMDp/ZxR6OTl/meyAyIxSHXC9tWw60XfSpdX5kPV7pehZCLUvw4dTX4Ck4ZqH8Je+xt0Nu9bp0V9sHv+1/56ThE8e5sPYh2N+5bpau2L5e87jcH0pf6xHU3+dAcVs33rX6IVSib7k4g37/Lhrup4sIhv6Ut1+vXkj/GPiUQglfDrieZAbhGk036f8sdoDInICBbaoKaujyIiIjLkusbKRfJh2hv8ZbCc810kY7n+ZyTuu1VufABmvtmPlXvy+76VrWCsD1Edzf40Bh1N/rxzE0/2gWzD/T7MRXPh0Zt8mLOID1vJ9sHVk1PkW+0yl48X+PV0Nvv7x87xXTx3rYXG7b47aPEE2PoUlM+ACSf7dWx9yofAEy+ByuN9nYl232rYuM3XWTHbrzedgD0boWKW7yoay4Pi8fue25ZaHxI7m33ABSiZ5INwXlnf4TGd9s+XyFEktEEtpen5RUREZCQxg/wy/3s8f9/tp3xg3+9v+szg1vWW6/b93tniw11RlW8Ra9zuT1NQMsn/3PminwiloNyHw2Q7NO3w4/Niub4FL7fItxY27/ZBqmwq1G+F2vWw+VG/rhPe5buD7nwBZp/tWwpX/8qvY/w8SKfgb/956M9P/hgfFBu3+a6jiVb81J0ZYvk+1CXbgeD5TLT6WsfN9RPExHL8egrK/Wygta/4FkiLBGML5/j9377ar3PyIh82O5r8enNLfKupmR+T2LjNPy6n0NdVOsmH1d0v+e6wlcdD4TgYM82vr3WPr60rWHY0Bc99MBlNcw1seghe/at/zPiT/Mndu8ZbppK+RbNwrG/tbG/wXWW7gqxzvrU0v9zva0O1f+67ti9HjdAGNY1RE5GR5s1vfjPXXHMN5513XvdtN910E+vXr+cHP/jBfsufddZZ3HjjjSxcuJC3v/3t/OpXv6KsrKzHMtdffz1FRUV89rOfPeh6brrpJlasWMGUKVP44he/yLx58w56HSIyAuQU+tapLiUT/QX8h/3Kfk5LcsoQbNu5ni1cHc0+GO1Y7QNPySRfS0eT7w6aW+wD05jpUPOy746ZaPNBs3mnDyVVJ/iwWTDW/47z9yc7fMBq2uEDmwFt9T4AHXcB7F7nWyddKhh32OyXGzN93yQxmQorfSh97hdD8ETg98ul+74vr9Q/F827obXW31ZQEUxkEzymq7Wws9W3tBZP8EE7nfTBcewxvgWybrMP0JGYf352rfXLVMzxz1XFHB/qzHyrZjzPt0zu2eRbgKtO8F1qd73o6xp/kn999ry6r6usc75FtXSS36+WWr+Nbav2hddX7/dh9JjzoWGrD5UT5vsvIbY+7e9zaR9Kx5/kJ/mpPAHqXvPLYz6cd13ySvzrnl/uH7v3Nd91uGCs/1tZf6+vp3SKr2XmWf5vv7DSB9umHT6gtzdA/Ra/rUjUP6+ttb6+nGDsaOlkv422Ov93un2171acaIf6zXDCxT5cgw/Okah/Dhuqg9BvA3cLTqeDWWhz/djUIyS8QU3T84vICLN8+XJWrFjRI6itWLGCr3/96wd87D333DPk9Xz605/m05/+9JCvV0SOIr0/aOUWwaQF/tLb+BN7Xi+ddOTqAv+h28x/WO5o2jfRy84XfUvcuLk+SNRv8R/wc4t9sGur80Eg0eJbEMdM98t1tvj11G32waVkAsw4E/Zs8EGh5hUfnorHA853Be2aAbTmZd/SNulU3wI3Yb5vRUt1+Ho2P+zDKPg6Cyp8y2XpZB90m3b6QNa0wz9vp3zAr2/rU3Dq5b5Fb+cLfn/3bPL1u3Swz20+jJzwLqheCRv+z4fZijm+vud/DZhvRW3du+98hH3JDKPjT/LL/+ULQZfZKKz8UbAP+X4b6SRMOx02/h88v+LwXs/SqX6cZ1dr6oNfPfR1WcQHuLa9/jVLJ3ve/+fPZuyr8/uXaPX3FVT4LwiKqvxrnFPog23bXl8X+Nc11QmnfxrO+dKh13kAoQ1q40vzeMvcSvLjOueJiIwMl156Kddddx2dnZ3k5OSwefNmtm/fzh133ME//dM/0dbWxqWXXsqXvrT/m/r06dNZtWoVY8eO5atf/Sq33norlZWVTJkyhVNP9bO//ehHP+KWW26hs7OT2bNn84tf/IKCggJ27drFVVddxaZNmzAzfvzjHzN37lyWLVtGXV0diUSCr3zlKyxbtgyAb3zjG/z0pz8F4IorrlCYE5Fwyjw9Qm6x/xmN9xxXaFF/Xr5MhRX7fu99X18Op8thJB+mLPKX4RLM44DZvnGTkah/jtJBcI3m+BbJxm2+W2XhOP+z6gSoWQfFE6G4ys9O2lLjw6RzvlXOpX24Tbb7sFwywd9X95oPvqWTYeyxfrn2eh8W2+r2hZ/mnT44VZ7ga2je7cdDVsz2QTmd9K1j21b5VtaWGh+6isf75SNxGDvbj+nEfIAqqPCBvbPVL1+/JVjvTN/aNvZYPwGPS/uWzPX3+u2Y+eeirc63sJVMhk0P+m017/ZBuLPZb6dw7L7nOBr3QXjaG4/oSxnaoHbGMeM445hx2S5DREaqe6/x3z4OpfHz4G039Ht3eXk5ixcv5t5772XZsmWsWLGC97znPVx77bWUl5eTSqU4++yzef755znppJP6XMczzzzDihUrWL16NclkkgULFnQHtYsvvpiPfvSjAFx33XX85Cc/4ZOf/CT/+I//yFve8hbuuusukskkra2t5OXlcdddd1FSUkJtbS2nnXYaF154Ic8++yw/+9nPeOqpp3DOsWTJEs4880xOOWUo+kiJiEjWZbaCZo6bBD8hS/mMfdfHHbv/4ydmHA9iOftaRs16Lh/Ph66hmGY+FPUOvvHxQQvkIOWV7Pt97jsGXnYwIbs/E0/u/76uGWBHAE2fIyIyhLq6P4Lv9rh8+XLuvPNOFixYwCmnnMLatWt56aWX+n38I488wkUXXURBQQElJSVceOGF3fe9+OKLLF26lHnz5nH77bezdu1aAB544AH+4R/+AYBYLEZJSQnOOa699lpOOukk3vrWt7Jt2zZ27drFo48+ykUXXURhYSFFRUVcfPHFPPLII0fwGREREZFDEdoWNRGRAQ3Q8nUkLVu2jM985jM8++yztLa2Ul5ezo033sjKlSsZM2YMl19+Oe3tg5xau5fLL7+cP/zhD8yfP5+f//znPPTQQ/0ue/vtt1NTU8MzzzxDPB5n+vTph7xdERERGX5qURMRGUJFRUW8+c1v5iMf+QjLly+nsbGRwsJCSktL2bVrF/fee++Ajz/jjDP4wx/+QFtbG01NTfzxj3/svq+pqYkJEyaQSCS4/fbbu28/++yz+eEPfwhAMpmksbGRhoYGKisricfjPPjgg2zZsgWApUuX8oc//IHW1lZaWlq46667WLp06RF4JkRERORwqEVNRGSILV++nIsuuogVK1Ywd+5cTjnlFObOncuUKVM4/fTTB3zsggULeO9738v8+fOprKxk0aJ9A9D//d//nSVLljBu3DiWLFlCU5Ofuetb3/oWH/3oR7nhhhuoqKjgZz/7Ge9///u54IILmDdvHgsXLmTu3Lnd67/88stZvHgx4CcT0fg0ERGRkcdc18www2zhwoVu1apVWdm2iIxO69at47jj+jmf0FHg8ccfZ/369Xz4wx/Oah19vQ5m9oxzbmGWSgodHSNFRI4OAx0f1fVRRGQUuOOOO/jgBz+I6eSSIiIio4K6PoqIjALLly9n+fKRM6WwiIiIHB61qImIiIiIiIwwCmoiMqpka9yteHr+RUREhoaCmoiMGnl5eezZs0dhIUucc+zZs4e8vLxslyIiIhJ6GqMmIqPG5MmTqa6upqamJtulHLXy8vKYPHlytssQEREJPQU1ERk14vE4M2bMyHYZIiIiIodNXR9FRERERERGGAU1ERERERGREUZBTUREREREZISxbM2OZmY1wJbDXM1YoHYIyhnptJ+ji/ZzdDka9nMo9nGac27cUBRzNNAx8qBoP0ePo2EfQfs52hzufvZ7fMxaUBsKZrbKObcw23UcadrP0UX7ObocDft5NOzjaHS0vG7az9HjaNhH0H6ONkdyP9X1UUREREREZIRRUBMRERERERlhwh7Ubsl2AcNE+zm6aD9Hl6NhP4+GfRyNjpbXTfs5ehwN+wjaz9HmiO1nqMeoiYiIiIiIjEZhb1ETEREREREZdUIb1MzsfDNbb2YbzOyabNczlMxss5m9YGarzWxVcFu5md1nZq8GP8dku86DZWY/NbPdZvZixm197pd53w5e3+fNbEH2Kj84/ezn9Wa2LXhNV5vZ2zPu+0Kwn+vN7LzsVH1wzGyKmT1oZi+Z2Voz+1Rw+6h6PQfYz9H2euaZ2dNmtibYzy8Ft88ws6eC/fm1meUEt+cG1zcE90/P6g5IDzo+6vg4Uh0Nx0c4Oo6ROj4O0/HRORe6CxAFNgIzgRxgDXB8tusawv3bDIztddvXgWuC368B/jPbdR7Cfp0BLABePNB+AW8H7gUMOA14Ktv1H+Z+Xg98to9ljw/+fnOBGcHfdTTb+zCIfZwALAh+LwZeCfZlVL2eA+znaHs9DSgKfo8DTwWv053AZcHtNwMfC36/Grg5+P0y4NfZ3gddul9LHR91fByxl6Ph+BjUPuqPkTo+Ds/xMawtaouBDc65Tc65TmAFsCzLNR1py4Bbg99vBd6VvVIOjXPuYWBvr5v7269lwG3OexIoM7MJw1LoYepnP/uzDFjhnOtwzr0GbMD/fY9ozrkdzrlng9+bgHXAJEbZ6znAfvYnrK+nc841B1fjwcUBbwF+G9ze+/Xsep1/C5xtZjY81coB6Pio4+OIdTQcH+HoOEbq+Dg8x8ewBrVJwNaM69UM/McRNg74q5k9Y2ZXBrdVOed2BL/vBKqyU9qQ62+/RuNr/ImgS8NPM7rmhH4/g2b9U/DfMo3a17PXfsIoez3NLGpmq4HdwH34bzvrnXPJYJHMfenez+D+BqBiWAuW/oT2b3CQdHwcna/xqHo/zXQ0HCN1fDxyx8ewBrXR7k3OuQXA24CPm9kZmXc635466qbrHK37FfgBMAs4GdgB/HdWqxkiZlYE/A74tHOuMfO+0fR69rGfo+71dM6lnHMnA5Px33LOzW5FIn3S8XH0GXXvp12OhmOkjo9HVliD2jZgSsb1ycFto4JzblvwczdwF/6PYldXM3jwc3f2KhxS/e3XqHqNnXO7gn/0NPAj9jX3h3Y/zSyOf3O+3Tn3++DmUfd69rWfo/H17OKcqwceBN6A734TC+7K3Jfu/QzuLwX2DG+l0o/Q/w0ORMdHYJS9xqP1/fRoOEbq+Hjkj49hDWorgTnBjCs5+MF6d2e5piFhZoVmVtz1O3Au8CJ+/z4ULPYh4H+yU+GQ62+/7gY+GMyEdBrQkNFdIHR69TW/CP+agt/Py4JZgmYAc4Cnh7u+gxX0t/4JsM45942Mu0bV69nffo7C13OcmZUFv+cD5+DHGzwIXBos1vv17HqdLwUeCL4dluzT8VHHx1AZbe+ncHQcI3V8HKbjY+/ZRcJywc+Q8wq+n+i/ZrueIdyvmfhZcdYAa7v2Dd+/9f+AV4H7gfJs13oI+3YHvhk8ge/P+/f97Rd+lp3vBa/vC8DCbNd/mPv5i2A/ng/+iSdkLP+vwX6uB96W7foHuY9vwnfZeB5YHVzePtpezwH2c7S9nicBzwX78yLwxeD2mfgD6QbgN0BucHtecH1DcP/MbO+DLj1eTx0fR0C9B7lvOj6OkvfToO5Rf4zU8XF4jo8WrFRERERERERGiLB2fRQRERERERm1FNRERERERERGGAU1ERERERGREUZBTUREREREZIRRUBMRERERERlhFNRERERERERGGAU1ERERERGREUZBTUREREREZIT5/y3h4BnBOPguAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(N_EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Treinamento')\n",
    "plt.plot(epochs_range, val_acc, label='Validação')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Acurácia de Treinamento e Validação (1)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Treinamento')\n",
    "plt.plot(epochs_range, val_loss, label='Validação')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Erro de Treinamento e Validação (2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00012-b7aae2de-c3fd-4cef-8134-c320a8a1ab65",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f'../model/trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "categories = [x.split('/')[-1].split('.')[0] for x in data_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "A partir da matriz de confusão gerada com as predições dos dados de teste, pode-se perceber que a média de acurácia é aproximadamente 90%, contudo há algumas classes que se distanciam desse valor. Por exemplo, a classe `bus` acurácia mais baixa que a média e pode-se perceber que há muitos falsos positivos, ou seja, o modelo acha que é um ônibus, mas na verdade não é, e a maioria desses falsos positivos são ambulâncias, o que é bem plausível. Esse mesmo fenômeno ocorre ao contrário. Além disso, isso ocorre com pássaros e aviões e também calendários e calculadoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions, normalize='pred')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=categories)\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "cmd.plot(ax=ax, xticks_rotation='vertical', values_format = '.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, obtivemos os dados de precision, recall e f1 score. A acurácia final do modelo foi de `88%`. Com esses dados, podemos ver que a classe `beach` possui um precision bem menor que o recall, o que pode ser comprovado na matriz de confusão. O eixo vertical dessa classe(tirando a predição certa) representa os falsos positivos, já o horizontal os falsos negativos. Como o precision é menor a soma desses valores do eixo vertical é maior do que as do eixo horizontal. Além disso, esses valores que representam os falsos positivos estão muito espalhados, o modelo acha que muitas categorias são `beach`, quando não são."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-d1665cad-bb47-4594-a5b0-e7e64469a6c1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names = categories)) "
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "c7f01c0c-2dc0-4900-a261-ef3e47813189",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
